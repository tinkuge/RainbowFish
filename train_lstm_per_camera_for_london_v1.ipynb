{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-24T19:49:26.171501Z",
     "start_time": "2019-05-24T19:49:26.156019Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "from time import time\n",
    "from datetime import datetime\n",
    "import itertools\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"-1\" #set to -1 to disable gpu (on fresh kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-24T19:49:35.155910Z",
     "start_time": "2019-05-24T19:49:26.390249Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-24T19:49:36.317033Z",
     "start_time": "2019-05-24T19:49:35.171616Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K.tensorflow_backend._get_available_gpus()\n",
    "# tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-24T19:49:36.973329Z",
     "start_time": "2019-05-24T19:49:36.332664Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-24T19:49:37.082663Z",
     "start_time": "2019-05-24T19:49:37.020121Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"cleandf_40days_930_to_1830_lin_interpolated.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-24T19:49:37.145121Z",
     "start_time": "2019-05-24T19:49:37.113912Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CAMERA_ID</th>\n",
       "      <th>TIMESTAMP</th>\n",
       "      <th>GEO_LON</th>\n",
       "      <th>GEO_LAT</th>\n",
       "      <th>DENSITY_VALUE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>2010-10-11 09:30:00</td>\n",
       "      <td>-0.227278</td>\n",
       "      <td>51.491661</td>\n",
       "      <td>53547.356500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>2010-10-11 10:00:00</td>\n",
       "      <td>-0.227278</td>\n",
       "      <td>51.491661</td>\n",
       "      <td>46199.700875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>2010-10-11 10:30:00</td>\n",
       "      <td>-0.227278</td>\n",
       "      <td>51.491661</td>\n",
       "      <td>39602.705900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2010-10-11 11:00:00</td>\n",
       "      <td>-0.227278</td>\n",
       "      <td>51.491661</td>\n",
       "      <td>27179.430333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2010-10-11 11:30:00</td>\n",
       "      <td>-0.227278</td>\n",
       "      <td>51.491661</td>\n",
       "      <td>23527.222300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>2010-10-11 12:00:00</td>\n",
       "      <td>-0.227278</td>\n",
       "      <td>51.491661</td>\n",
       "      <td>19940.461500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "      <td>2010-10-11 12:30:00</td>\n",
       "      <td>-0.227278</td>\n",
       "      <td>51.491661</td>\n",
       "      <td>20405.220000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4</td>\n",
       "      <td>2010-10-11 13:00:00</td>\n",
       "      <td>-0.227278</td>\n",
       "      <td>51.491661</td>\n",
       "      <td>21775.247000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4</td>\n",
       "      <td>2010-10-11 13:30:00</td>\n",
       "      <td>-0.227278</td>\n",
       "      <td>51.491661</td>\n",
       "      <td>18727.309900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4</td>\n",
       "      <td>2010-10-11 14:00:00</td>\n",
       "      <td>-0.227278</td>\n",
       "      <td>51.491661</td>\n",
       "      <td>17784.156700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CAMERA_ID            TIMESTAMP   GEO_LON    GEO_LAT  DENSITY_VALUE\n",
       "0          4  2010-10-11 09:30:00 -0.227278  51.491661   53547.356500\n",
       "1          4  2010-10-11 10:00:00 -0.227278  51.491661   46199.700875\n",
       "2          4  2010-10-11 10:30:00 -0.227278  51.491661   39602.705900\n",
       "3          4  2010-10-11 11:00:00 -0.227278  51.491661   27179.430333\n",
       "4          4  2010-10-11 11:30:00 -0.227278  51.491661   23527.222300\n",
       "5          4  2010-10-11 12:00:00 -0.227278  51.491661   19940.461500\n",
       "6          4  2010-10-11 12:30:00 -0.227278  51.491661   20405.220000\n",
       "7          4  2010-10-11 13:00:00 -0.227278  51.491661   21775.247000\n",
       "8          4  2010-10-11 13:30:00 -0.227278  51.491661   18727.309900\n",
       "9          4  2010-10-11 14:00:00 -0.227278  51.491661   17784.156700"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-24T19:49:37.207621Z",
     "start_time": "2019-05-24T19:49:37.160808Z"
    }
   },
   "outputs": [],
   "source": [
    "# df.DENSITY_VALUE = np.log(df.DENSITY_VALUE)\n",
    "#print(df.DENSITY_VALUE)\n",
    "#print(df.DENSITY_VALUE.min())\n",
    "df.DENSITY_VALUE -= df.DENSITY_VALUE.min()\n",
    "#print(df.DENSITY_VALUE.max())\n",
    "df.DENSITY_VALUE /= df.DENSITY_VALUE.max() # scaling to [0,1]\n",
    "df = df.pivot(index=\"TIMESTAMP\",columns=\"CAMERA_ID\",values=\"DENSITY_VALUE\")\n",
    "L = int(0.75 * len(df)) #3/4 of the length of data (over time) to be used as train and what ever comes after this would be for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-24T19:51:25.433030Z",
     "start_time": "2019-05-24T19:51:25.370665Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>CAMERA_ID</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>15</th>\n",
       "      <th>20</th>\n",
       "      <th>26</th>\n",
       "      <th>30</th>\n",
       "      <th>...</th>\n",
       "      <th>98</th>\n",
       "      <th>101</th>\n",
       "      <th>103</th>\n",
       "      <th>107</th>\n",
       "      <th>108</th>\n",
       "      <th>111</th>\n",
       "      <th>117</th>\n",
       "      <th>118</th>\n",
       "      <th>119</th>\n",
       "      <th>120</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TIMESTAMP</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-10-11 09:30:00</th>\n",
       "      <td>0.832721</td>\n",
       "      <td>0.736465</td>\n",
       "      <td>0.673375</td>\n",
       "      <td>0.875612</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.722307</td>\n",
       "      <td>0.757152</td>\n",
       "      <td>0.680594</td>\n",
       "      <td>0.665648</td>\n",
       "      <td>0.684109</td>\n",
       "      <td>...</td>\n",
       "      <td>0.829776</td>\n",
       "      <td>0.784347</td>\n",
       "      <td>0.683784</td>\n",
       "      <td>0.690634</td>\n",
       "      <td>0.841041</td>\n",
       "      <td>0.767792</td>\n",
       "      <td>0.692569</td>\n",
       "      <td>0.767109</td>\n",
       "      <td>0.918728</td>\n",
       "      <td>0.862367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-10-11 10:00:00</th>\n",
       "      <td>0.717267</td>\n",
       "      <td>0.677046</td>\n",
       "      <td>0.539202</td>\n",
       "      <td>0.536337</td>\n",
       "      <td>0.928692</td>\n",
       "      <td>0.588867</td>\n",
       "      <td>0.552925</td>\n",
       "      <td>0.475241</td>\n",
       "      <td>0.500489</td>\n",
       "      <td>0.403454</td>\n",
       "      <td>...</td>\n",
       "      <td>0.758407</td>\n",
       "      <td>0.623102</td>\n",
       "      <td>0.457033</td>\n",
       "      <td>0.578736</td>\n",
       "      <td>0.778317</td>\n",
       "      <td>0.819475</td>\n",
       "      <td>0.549714</td>\n",
       "      <td>0.579417</td>\n",
       "      <td>0.716728</td>\n",
       "      <td>0.710952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-10-11 10:30:00</th>\n",
       "      <td>0.613608</td>\n",
       "      <td>0.580922</td>\n",
       "      <td>0.429255</td>\n",
       "      <td>0.479447</td>\n",
       "      <td>0.857383</td>\n",
       "      <td>0.536391</td>\n",
       "      <td>0.478475</td>\n",
       "      <td>0.367212</td>\n",
       "      <td>0.572155</td>\n",
       "      <td>0.488556</td>\n",
       "      <td>...</td>\n",
       "      <td>0.763662</td>\n",
       "      <td>0.777090</td>\n",
       "      <td>0.536671</td>\n",
       "      <td>0.652575</td>\n",
       "      <td>0.764758</td>\n",
       "      <td>0.828405</td>\n",
       "      <td>0.575197</td>\n",
       "      <td>0.616658</td>\n",
       "      <td>0.675727</td>\n",
       "      <td>0.736828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-10-11 11:00:00</th>\n",
       "      <td>0.418400</td>\n",
       "      <td>0.434257</td>\n",
       "      <td>0.266390</td>\n",
       "      <td>0.339875</td>\n",
       "      <td>0.725234</td>\n",
       "      <td>0.430256</td>\n",
       "      <td>0.267442</td>\n",
       "      <td>0.182961</td>\n",
       "      <td>0.365195</td>\n",
       "      <td>0.352724</td>\n",
       "      <td>...</td>\n",
       "      <td>0.622577</td>\n",
       "      <td>0.653502</td>\n",
       "      <td>0.499189</td>\n",
       "      <td>0.514473</td>\n",
       "      <td>0.577114</td>\n",
       "      <td>0.595619</td>\n",
       "      <td>0.433528</td>\n",
       "      <td>0.578645</td>\n",
       "      <td>0.592677</td>\n",
       "      <td>0.620731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-10-11 11:30:00</th>\n",
       "      <td>0.361012</td>\n",
       "      <td>0.404033</td>\n",
       "      <td>0.204576</td>\n",
       "      <td>0.306596</td>\n",
       "      <td>0.321575</td>\n",
       "      <td>0.389043</td>\n",
       "      <td>0.256184</td>\n",
       "      <td>0.179937</td>\n",
       "      <td>0.287719</td>\n",
       "      <td>0.352193</td>\n",
       "      <td>...</td>\n",
       "      <td>0.551073</td>\n",
       "      <td>0.404707</td>\n",
       "      <td>0.391159</td>\n",
       "      <td>0.448867</td>\n",
       "      <td>0.491578</td>\n",
       "      <td>0.472831</td>\n",
       "      <td>0.432047</td>\n",
       "      <td>0.497837</td>\n",
       "      <td>0.537321</td>\n",
       "      <td>0.566835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-10-11 12:00:00</th>\n",
       "      <td>0.304653</td>\n",
       "      <td>0.428367</td>\n",
       "      <td>0.183852</td>\n",
       "      <td>0.274417</td>\n",
       "      <td>0.289617</td>\n",
       "      <td>0.390220</td>\n",
       "      <td>0.238520</td>\n",
       "      <td>0.251622</td>\n",
       "      <td>0.230938</td>\n",
       "      <td>0.302200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.400982</td>\n",
       "      <td>0.298795</td>\n",
       "      <td>0.360811</td>\n",
       "      <td>0.400292</td>\n",
       "      <td>0.475637</td>\n",
       "      <td>0.434021</td>\n",
       "      <td>0.443339</td>\n",
       "      <td>0.384552</td>\n",
       "      <td>0.416145</td>\n",
       "      <td>0.502617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-10-11 12:30:00</th>\n",
       "      <td>0.311956</td>\n",
       "      <td>0.304918</td>\n",
       "      <td>0.206830</td>\n",
       "      <td>0.266901</td>\n",
       "      <td>0.291421</td>\n",
       "      <td>0.414603</td>\n",
       "      <td>0.269281</td>\n",
       "      <td>0.253575</td>\n",
       "      <td>0.284814</td>\n",
       "      <td>0.249794</td>\n",
       "      <td>...</td>\n",
       "      <td>0.373132</td>\n",
       "      <td>0.264625</td>\n",
       "      <td>0.333265</td>\n",
       "      <td>0.376261</td>\n",
       "      <td>0.433424</td>\n",
       "      <td>0.433238</td>\n",
       "      <td>0.462217</td>\n",
       "      <td>0.432484</td>\n",
       "      <td>0.382512</td>\n",
       "      <td>0.483837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-10-11 13:00:00</th>\n",
       "      <td>0.333483</td>\n",
       "      <td>0.316085</td>\n",
       "      <td>0.242929</td>\n",
       "      <td>0.242035</td>\n",
       "      <td>0.285842</td>\n",
       "      <td>0.357791</td>\n",
       "      <td>0.320907</td>\n",
       "      <td>0.263375</td>\n",
       "      <td>0.325637</td>\n",
       "      <td>0.223476</td>\n",
       "      <td>...</td>\n",
       "      <td>0.487796</td>\n",
       "      <td>0.283220</td>\n",
       "      <td>0.318404</td>\n",
       "      <td>0.454659</td>\n",
       "      <td>0.450762</td>\n",
       "      <td>0.426478</td>\n",
       "      <td>0.391113</td>\n",
       "      <td>0.390846</td>\n",
       "      <td>0.378882</td>\n",
       "      <td>0.507946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-10-11 13:30:00</th>\n",
       "      <td>0.285591</td>\n",
       "      <td>0.366087</td>\n",
       "      <td>0.161221</td>\n",
       "      <td>0.244930</td>\n",
       "      <td>0.305829</td>\n",
       "      <td>0.303704</td>\n",
       "      <td>0.377544</td>\n",
       "      <td>0.264186</td>\n",
       "      <td>0.344778</td>\n",
       "      <td>0.177547</td>\n",
       "      <td>...</td>\n",
       "      <td>0.508135</td>\n",
       "      <td>0.304850</td>\n",
       "      <td>0.298616</td>\n",
       "      <td>0.483756</td>\n",
       "      <td>0.410347</td>\n",
       "      <td>0.475361</td>\n",
       "      <td>0.333088</td>\n",
       "      <td>0.451806</td>\n",
       "      <td>0.526446</td>\n",
       "      <td>0.457300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-10-11 14:00:00</th>\n",
       "      <td>0.270771</td>\n",
       "      <td>0.277595</td>\n",
       "      <td>0.120844</td>\n",
       "      <td>0.226747</td>\n",
       "      <td>0.304305</td>\n",
       "      <td>0.256422</td>\n",
       "      <td>0.342459</td>\n",
       "      <td>0.238910</td>\n",
       "      <td>0.360085</td>\n",
       "      <td>0.181137</td>\n",
       "      <td>...</td>\n",
       "      <td>0.555788</td>\n",
       "      <td>0.290470</td>\n",
       "      <td>0.261859</td>\n",
       "      <td>0.368063</td>\n",
       "      <td>0.380744</td>\n",
       "      <td>0.423746</td>\n",
       "      <td>0.318768</td>\n",
       "      <td>0.446765</td>\n",
       "      <td>0.521514</td>\n",
       "      <td>0.436164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-10-11 14:30:00</th>\n",
       "      <td>0.341074</td>\n",
       "      <td>0.261700</td>\n",
       "      <td>0.137740</td>\n",
       "      <td>0.218907</td>\n",
       "      <td>0.317512</td>\n",
       "      <td>0.353358</td>\n",
       "      <td>0.300350</td>\n",
       "      <td>0.246336</td>\n",
       "      <td>0.385627</td>\n",
       "      <td>0.205027</td>\n",
       "      <td>...</td>\n",
       "      <td>0.572042</td>\n",
       "      <td>0.275689</td>\n",
       "      <td>0.261115</td>\n",
       "      <td>0.322878</td>\n",
       "      <td>0.380237</td>\n",
       "      <td>0.402009</td>\n",
       "      <td>0.289831</td>\n",
       "      <td>0.438747</td>\n",
       "      <td>0.325464</td>\n",
       "      <td>0.421445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-10-11 15:00:00</th>\n",
       "      <td>0.340054</td>\n",
       "      <td>0.229100</td>\n",
       "      <td>0.138745</td>\n",
       "      <td>0.260715</td>\n",
       "      <td>0.348867</td>\n",
       "      <td>0.419101</td>\n",
       "      <td>0.346580</td>\n",
       "      <td>0.291746</td>\n",
       "      <td>0.423853</td>\n",
       "      <td>0.268816</td>\n",
       "      <td>...</td>\n",
       "      <td>0.542959</td>\n",
       "      <td>0.298133</td>\n",
       "      <td>0.317831</td>\n",
       "      <td>0.293275</td>\n",
       "      <td>0.409033</td>\n",
       "      <td>0.433741</td>\n",
       "      <td>0.354654</td>\n",
       "      <td>0.454054</td>\n",
       "      <td>0.275597</td>\n",
       "      <td>0.513977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-10-11 15:30:00</th>\n",
       "      <td>0.423740</td>\n",
       "      <td>0.220598</td>\n",
       "      <td>0.203397</td>\n",
       "      <td>0.377745</td>\n",
       "      <td>0.419855</td>\n",
       "      <td>0.562095</td>\n",
       "      <td>0.361028</td>\n",
       "      <td>0.377177</td>\n",
       "      <td>0.414986</td>\n",
       "      <td>0.305366</td>\n",
       "      <td>...</td>\n",
       "      <td>0.476663</td>\n",
       "      <td>0.397092</td>\n",
       "      <td>0.522405</td>\n",
       "      <td>0.322164</td>\n",
       "      <td>0.479857</td>\n",
       "      <td>0.409845</td>\n",
       "      <td>0.377025</td>\n",
       "      <td>0.538367</td>\n",
       "      <td>0.305541</td>\n",
       "      <td>0.673131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-10-11 16:00:00</th>\n",
       "      <td>0.446975</td>\n",
       "      <td>0.241334</td>\n",
       "      <td>0.160889</td>\n",
       "      <td>0.402249</td>\n",
       "      <td>0.513418</td>\n",
       "      <td>0.522618</td>\n",
       "      <td>0.454824</td>\n",
       "      <td>0.404235</td>\n",
       "      <td>0.399235</td>\n",
       "      <td>0.299559</td>\n",
       "      <td>...</td>\n",
       "      <td>0.419207</td>\n",
       "      <td>0.471665</td>\n",
       "      <td>0.529905</td>\n",
       "      <td>0.343290</td>\n",
       "      <td>0.579164</td>\n",
       "      <td>0.422125</td>\n",
       "      <td>0.359624</td>\n",
       "      <td>0.519280</td>\n",
       "      <td>0.303601</td>\n",
       "      <td>0.707524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-10-11 16:30:00</th>\n",
       "      <td>0.541662</td>\n",
       "      <td>0.373131</td>\n",
       "      <td>0.179553</td>\n",
       "      <td>0.452027</td>\n",
       "      <td>0.634326</td>\n",
       "      <td>0.523552</td>\n",
       "      <td>0.572142</td>\n",
       "      <td>0.415623</td>\n",
       "      <td>0.422166</td>\n",
       "      <td>0.342624</td>\n",
       "      <td>...</td>\n",
       "      <td>0.371676</td>\n",
       "      <td>0.551738</td>\n",
       "      <td>0.529345</td>\n",
       "      <td>0.464809</td>\n",
       "      <td>0.662418</td>\n",
       "      <td>0.589568</td>\n",
       "      <td>0.444026</td>\n",
       "      <td>0.535060</td>\n",
       "      <td>0.441724</td>\n",
       "      <td>0.499553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-10-11 17:00:00</th>\n",
       "      <td>0.623828</td>\n",
       "      <td>0.570275</td>\n",
       "      <td>0.421990</td>\n",
       "      <td>0.577903</td>\n",
       "      <td>0.686852</td>\n",
       "      <td>0.536800</td>\n",
       "      <td>0.703394</td>\n",
       "      <td>0.413542</td>\n",
       "      <td>0.478655</td>\n",
       "      <td>0.372564</td>\n",
       "      <td>...</td>\n",
       "      <td>0.386228</td>\n",
       "      <td>0.538251</td>\n",
       "      <td>0.473158</td>\n",
       "      <td>0.544584</td>\n",
       "      <td>0.700178</td>\n",
       "      <td>0.691329</td>\n",
       "      <td>0.507410</td>\n",
       "      <td>0.580030</td>\n",
       "      <td>0.626056</td>\n",
       "      <td>0.394785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-10-11 17:30:00</th>\n",
       "      <td>0.560180</td>\n",
       "      <td>0.649326</td>\n",
       "      <td>0.449701</td>\n",
       "      <td>0.601893</td>\n",
       "      <td>0.650849</td>\n",
       "      <td>0.549598</td>\n",
       "      <td>0.656522</td>\n",
       "      <td>0.457139</td>\n",
       "      <td>0.607575</td>\n",
       "      <td>0.329682</td>\n",
       "      <td>...</td>\n",
       "      <td>0.414344</td>\n",
       "      <td>0.647150</td>\n",
       "      <td>0.440155</td>\n",
       "      <td>0.634593</td>\n",
       "      <td>0.733539</td>\n",
       "      <td>0.642168</td>\n",
       "      <td>0.563282</td>\n",
       "      <td>0.593026</td>\n",
       "      <td>0.646877</td>\n",
       "      <td>0.369479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-10-11 18:00:00</th>\n",
       "      <td>0.479465</td>\n",
       "      <td>0.583546</td>\n",
       "      <td>0.507219</td>\n",
       "      <td>0.368292</td>\n",
       "      <td>0.548068</td>\n",
       "      <td>0.559417</td>\n",
       "      <td>0.439797</td>\n",
       "      <td>0.442055</td>\n",
       "      <td>0.490930</td>\n",
       "      <td>0.256381</td>\n",
       "      <td>...</td>\n",
       "      <td>0.396956</td>\n",
       "      <td>0.603948</td>\n",
       "      <td>0.458544</td>\n",
       "      <td>0.443475</td>\n",
       "      <td>0.679777</td>\n",
       "      <td>0.548853</td>\n",
       "      <td>0.442438</td>\n",
       "      <td>0.540490</td>\n",
       "      <td>0.440417</td>\n",
       "      <td>0.400268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-10-11 18:30:00</th>\n",
       "      <td>0.628765</td>\n",
       "      <td>0.642776</td>\n",
       "      <td>0.650817</td>\n",
       "      <td>0.734953</td>\n",
       "      <td>0.703240</td>\n",
       "      <td>0.727471</td>\n",
       "      <td>0.754835</td>\n",
       "      <td>0.650868</td>\n",
       "      <td>0.681445</td>\n",
       "      <td>0.484290</td>\n",
       "      <td>...</td>\n",
       "      <td>0.689894</td>\n",
       "      <td>0.688225</td>\n",
       "      <td>0.828009</td>\n",
       "      <td>0.734000</td>\n",
       "      <td>0.794301</td>\n",
       "      <td>0.629404</td>\n",
       "      <td>0.657569</td>\n",
       "      <td>0.623442</td>\n",
       "      <td>0.525996</td>\n",
       "      <td>0.667932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-10-12 09:30:00</th>\n",
       "      <td>0.406132</td>\n",
       "      <td>0.432930</td>\n",
       "      <td>0.527475</td>\n",
       "      <td>0.311408</td>\n",
       "      <td>0.440725</td>\n",
       "      <td>0.481055</td>\n",
       "      <td>0.682421</td>\n",
       "      <td>0.364472</td>\n",
       "      <td>0.554761</td>\n",
       "      <td>0.393615</td>\n",
       "      <td>...</td>\n",
       "      <td>0.553459</td>\n",
       "      <td>0.621870</td>\n",
       "      <td>0.661458</td>\n",
       "      <td>0.313904</td>\n",
       "      <td>0.539148</td>\n",
       "      <td>0.537466</td>\n",
       "      <td>0.348860</td>\n",
       "      <td>0.388840</td>\n",
       "      <td>0.356299</td>\n",
       "      <td>0.392526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-10-12 10:00:00</th>\n",
       "      <td>0.394718</td>\n",
       "      <td>0.422405</td>\n",
       "      <td>0.492325</td>\n",
       "      <td>0.321751</td>\n",
       "      <td>0.387691</td>\n",
       "      <td>0.502979</td>\n",
       "      <td>0.651874</td>\n",
       "      <td>0.366705</td>\n",
       "      <td>0.442578</td>\n",
       "      <td>0.371921</td>\n",
       "      <td>...</td>\n",
       "      <td>0.535841</td>\n",
       "      <td>0.594163</td>\n",
       "      <td>0.652359</td>\n",
       "      <td>0.291397</td>\n",
       "      <td>0.455822</td>\n",
       "      <td>0.614017</td>\n",
       "      <td>0.305964</td>\n",
       "      <td>0.339388</td>\n",
       "      <td>0.313437</td>\n",
       "      <td>0.357183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-10-12 10:30:00</th>\n",
       "      <td>0.392652</td>\n",
       "      <td>0.406920</td>\n",
       "      <td>0.370317</td>\n",
       "      <td>0.259585</td>\n",
       "      <td>0.292303</td>\n",
       "      <td>0.439099</td>\n",
       "      <td>0.369541</td>\n",
       "      <td>0.317714</td>\n",
       "      <td>0.378675</td>\n",
       "      <td>0.311229</td>\n",
       "      <td>...</td>\n",
       "      <td>0.449602</td>\n",
       "      <td>0.569645</td>\n",
       "      <td>0.616223</td>\n",
       "      <td>0.257318</td>\n",
       "      <td>0.410808</td>\n",
       "      <td>0.594062</td>\n",
       "      <td>0.207295</td>\n",
       "      <td>0.316366</td>\n",
       "      <td>0.302657</td>\n",
       "      <td>0.356199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-10-12 11:00:00</th>\n",
       "      <td>0.350642</td>\n",
       "      <td>0.374163</td>\n",
       "      <td>0.342122</td>\n",
       "      <td>0.231752</td>\n",
       "      <td>0.261941</td>\n",
       "      <td>0.431046</td>\n",
       "      <td>0.256147</td>\n",
       "      <td>0.263220</td>\n",
       "      <td>0.268949</td>\n",
       "      <td>0.263107</td>\n",
       "      <td>...</td>\n",
       "      <td>0.388755</td>\n",
       "      <td>0.521915</td>\n",
       "      <td>0.619089</td>\n",
       "      <td>0.293859</td>\n",
       "      <td>0.463861</td>\n",
       "      <td>0.551128</td>\n",
       "      <td>0.177354</td>\n",
       "      <td>0.404294</td>\n",
       "      <td>0.243649</td>\n",
       "      <td>0.367306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-10-12 11:30:00</th>\n",
       "      <td>0.377405</td>\n",
       "      <td>0.408138</td>\n",
       "      <td>0.316887</td>\n",
       "      <td>0.222012</td>\n",
       "      <td>0.282189</td>\n",
       "      <td>0.430658</td>\n",
       "      <td>0.234854</td>\n",
       "      <td>0.192700</td>\n",
       "      <td>0.231466</td>\n",
       "      <td>0.235408</td>\n",
       "      <td>...</td>\n",
       "      <td>0.382010</td>\n",
       "      <td>0.527725</td>\n",
       "      <td>0.808275</td>\n",
       "      <td>0.271848</td>\n",
       "      <td>0.486010</td>\n",
       "      <td>0.563133</td>\n",
       "      <td>0.208546</td>\n",
       "      <td>0.355715</td>\n",
       "      <td>0.219783</td>\n",
       "      <td>0.520785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-10-12 12:00:00</th>\n",
       "      <td>0.329586</td>\n",
       "      <td>0.327265</td>\n",
       "      <td>0.299036</td>\n",
       "      <td>0.263719</td>\n",
       "      <td>0.256575</td>\n",
       "      <td>0.383583</td>\n",
       "      <td>0.237543</td>\n",
       "      <td>0.195561</td>\n",
       "      <td>0.218082</td>\n",
       "      <td>0.214458</td>\n",
       "      <td>...</td>\n",
       "      <td>0.402677</td>\n",
       "      <td>0.489514</td>\n",
       "      <td>0.742377</td>\n",
       "      <td>0.256742</td>\n",
       "      <td>0.454464</td>\n",
       "      <td>0.527450</td>\n",
       "      <td>0.177078</td>\n",
       "      <td>0.309275</td>\n",
       "      <td>0.216600</td>\n",
       "      <td>0.511947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-10-12 12:30:00</th>\n",
       "      <td>0.283286</td>\n",
       "      <td>0.299494</td>\n",
       "      <td>0.354648</td>\n",
       "      <td>0.235572</td>\n",
       "      <td>0.246865</td>\n",
       "      <td>0.374685</td>\n",
       "      <td>0.375374</td>\n",
       "      <td>0.304679</td>\n",
       "      <td>0.334134</td>\n",
       "      <td>0.199777</td>\n",
       "      <td>...</td>\n",
       "      <td>0.432488</td>\n",
       "      <td>0.354795</td>\n",
       "      <td>0.535441</td>\n",
       "      <td>0.253927</td>\n",
       "      <td>0.410649</td>\n",
       "      <td>0.477343</td>\n",
       "      <td>0.140617</td>\n",
       "      <td>0.308512</td>\n",
       "      <td>0.172058</td>\n",
       "      <td>0.501595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-10-12 13:00:00</th>\n",
       "      <td>0.267242</td>\n",
       "      <td>0.295020</td>\n",
       "      <td>0.316561</td>\n",
       "      <td>0.288581</td>\n",
       "      <td>0.269757</td>\n",
       "      <td>0.344458</td>\n",
       "      <td>0.441813</td>\n",
       "      <td>0.427538</td>\n",
       "      <td>0.396001</td>\n",
       "      <td>0.223278</td>\n",
       "      <td>...</td>\n",
       "      <td>0.458570</td>\n",
       "      <td>0.352001</td>\n",
       "      <td>0.484725</td>\n",
       "      <td>0.253990</td>\n",
       "      <td>0.445762</td>\n",
       "      <td>0.495733</td>\n",
       "      <td>0.172163</td>\n",
       "      <td>0.306449</td>\n",
       "      <td>0.178023</td>\n",
       "      <td>0.474232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-10-12 13:30:00</th>\n",
       "      <td>0.223575</td>\n",
       "      <td>0.271862</td>\n",
       "      <td>0.322887</td>\n",
       "      <td>0.327436</td>\n",
       "      <td>0.297633</td>\n",
       "      <td>0.287486</td>\n",
       "      <td>0.453984</td>\n",
       "      <td>0.309188</td>\n",
       "      <td>0.429086</td>\n",
       "      <td>0.199601</td>\n",
       "      <td>...</td>\n",
       "      <td>0.488456</td>\n",
       "      <td>0.294045</td>\n",
       "      <td>0.448668</td>\n",
       "      <td>0.359512</td>\n",
       "      <td>0.410957</td>\n",
       "      <td>0.458989</td>\n",
       "      <td>0.172077</td>\n",
       "      <td>0.272916</td>\n",
       "      <td>0.261179</td>\n",
       "      <td>0.445273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-10-12 14:00:00</th>\n",
       "      <td>0.185948</td>\n",
       "      <td>0.245146</td>\n",
       "      <td>0.319398</td>\n",
       "      <td>0.343789</td>\n",
       "      <td>0.259786</td>\n",
       "      <td>0.311129</td>\n",
       "      <td>0.488415</td>\n",
       "      <td>0.301947</td>\n",
       "      <td>0.465054</td>\n",
       "      <td>0.192551</td>\n",
       "      <td>...</td>\n",
       "      <td>0.507368</td>\n",
       "      <td>0.246207</td>\n",
       "      <td>0.433282</td>\n",
       "      <td>0.292105</td>\n",
       "      <td>0.458807</td>\n",
       "      <td>0.440723</td>\n",
       "      <td>0.212970</td>\n",
       "      <td>0.304422</td>\n",
       "      <td>0.225522</td>\n",
       "      <td>0.448808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-10-12 14:30:00</th>\n",
       "      <td>0.181039</td>\n",
       "      <td>0.239531</td>\n",
       "      <td>0.266494</td>\n",
       "      <td>0.309499</td>\n",
       "      <td>0.328422</td>\n",
       "      <td>0.335283</td>\n",
       "      <td>0.470166</td>\n",
       "      <td>0.311311</td>\n",
       "      <td>0.461646</td>\n",
       "      <td>0.190035</td>\n",
       "      <td>...</td>\n",
       "      <td>0.469791</td>\n",
       "      <td>0.331082</td>\n",
       "      <td>0.419413</td>\n",
       "      <td>0.306579</td>\n",
       "      <td>0.427612</td>\n",
       "      <td>0.431576</td>\n",
       "      <td>0.241121</td>\n",
       "      <td>0.293958</td>\n",
       "      <td>0.144914</td>\n",
       "      <td>0.470750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-21 13:30:00</th>\n",
       "      <td>0.113510</td>\n",
       "      <td>0.230744</td>\n",
       "      <td>0.109129</td>\n",
       "      <td>0.061064</td>\n",
       "      <td>0.079682</td>\n",
       "      <td>0.091333</td>\n",
       "      <td>0.153531</td>\n",
       "      <td>0.206270</td>\n",
       "      <td>0.086193</td>\n",
       "      <td>0.037398</td>\n",
       "      <td>...</td>\n",
       "      <td>0.110223</td>\n",
       "      <td>0.264634</td>\n",
       "      <td>0.199198</td>\n",
       "      <td>0.189720</td>\n",
       "      <td>0.111470</td>\n",
       "      <td>0.181396</td>\n",
       "      <td>0.070860</td>\n",
       "      <td>0.172657</td>\n",
       "      <td>0.087835</td>\n",
       "      <td>0.224782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-21 14:00:00</th>\n",
       "      <td>0.156925</td>\n",
       "      <td>0.237202</td>\n",
       "      <td>0.288286</td>\n",
       "      <td>0.073161</td>\n",
       "      <td>0.080484</td>\n",
       "      <td>0.097429</td>\n",
       "      <td>0.128835</td>\n",
       "      <td>0.200623</td>\n",
       "      <td>0.089523</td>\n",
       "      <td>0.051702</td>\n",
       "      <td>...</td>\n",
       "      <td>0.111614</td>\n",
       "      <td>0.273451</td>\n",
       "      <td>0.191858</td>\n",
       "      <td>0.146628</td>\n",
       "      <td>0.119255</td>\n",
       "      <td>0.172107</td>\n",
       "      <td>0.109352</td>\n",
       "      <td>0.119709</td>\n",
       "      <td>0.099634</td>\n",
       "      <td>0.245257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-21 14:30:00</th>\n",
       "      <td>0.067753</td>\n",
       "      <td>0.219193</td>\n",
       "      <td>0.094437</td>\n",
       "      <td>0.070939</td>\n",
       "      <td>0.168746</td>\n",
       "      <td>0.126417</td>\n",
       "      <td>0.108765</td>\n",
       "      <td>0.229881</td>\n",
       "      <td>0.074526</td>\n",
       "      <td>0.049713</td>\n",
       "      <td>...</td>\n",
       "      <td>0.091772</td>\n",
       "      <td>0.291459</td>\n",
       "      <td>0.166140</td>\n",
       "      <td>0.146256</td>\n",
       "      <td>0.111709</td>\n",
       "      <td>0.188251</td>\n",
       "      <td>0.045930</td>\n",
       "      <td>0.117796</td>\n",
       "      <td>0.114633</td>\n",
       "      <td>0.199181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-21 15:00:00</th>\n",
       "      <td>0.068327</td>\n",
       "      <td>0.203660</td>\n",
       "      <td>0.091436</td>\n",
       "      <td>0.062752</td>\n",
       "      <td>0.126965</td>\n",
       "      <td>0.187496</td>\n",
       "      <td>0.089046</td>\n",
       "      <td>0.188985</td>\n",
       "      <td>0.075719</td>\n",
       "      <td>0.043633</td>\n",
       "      <td>...</td>\n",
       "      <td>0.095344</td>\n",
       "      <td>0.264108</td>\n",
       "      <td>0.160452</td>\n",
       "      <td>0.141558</td>\n",
       "      <td>0.130020</td>\n",
       "      <td>0.179787</td>\n",
       "      <td>0.114821</td>\n",
       "      <td>0.152087</td>\n",
       "      <td>0.126461</td>\n",
       "      <td>0.225532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-21 15:30:00</th>\n",
       "      <td>0.092746</td>\n",
       "      <td>0.214257</td>\n",
       "      <td>0.125261</td>\n",
       "      <td>0.092806</td>\n",
       "      <td>0.169692</td>\n",
       "      <td>0.185095</td>\n",
       "      <td>0.165188</td>\n",
       "      <td>0.175775</td>\n",
       "      <td>0.113867</td>\n",
       "      <td>0.118803</td>\n",
       "      <td>...</td>\n",
       "      <td>0.102777</td>\n",
       "      <td>0.284151</td>\n",
       "      <td>0.233905</td>\n",
       "      <td>0.166304</td>\n",
       "      <td>0.118396</td>\n",
       "      <td>0.154542</td>\n",
       "      <td>0.084295</td>\n",
       "      <td>0.135187</td>\n",
       "      <td>0.095699</td>\n",
       "      <td>0.249253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-21 16:00:00</th>\n",
       "      <td>0.286689</td>\n",
       "      <td>0.291706</td>\n",
       "      <td>0.427269</td>\n",
       "      <td>0.530477</td>\n",
       "      <td>0.516520</td>\n",
       "      <td>0.373795</td>\n",
       "      <td>0.438778</td>\n",
       "      <td>0.540753</td>\n",
       "      <td>0.405293</td>\n",
       "      <td>0.244701</td>\n",
       "      <td>...</td>\n",
       "      <td>0.411930</td>\n",
       "      <td>0.346484</td>\n",
       "      <td>0.564950</td>\n",
       "      <td>0.303317</td>\n",
       "      <td>0.396241</td>\n",
       "      <td>0.255057</td>\n",
       "      <td>0.185105</td>\n",
       "      <td>0.259899</td>\n",
       "      <td>0.169617</td>\n",
       "      <td>0.386337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-21 16:30:00</th>\n",
       "      <td>0.466970</td>\n",
       "      <td>0.267430</td>\n",
       "      <td>0.619214</td>\n",
       "      <td>0.550645</td>\n",
       "      <td>0.730653</td>\n",
       "      <td>0.681642</td>\n",
       "      <td>0.662437</td>\n",
       "      <td>0.580334</td>\n",
       "      <td>0.556491</td>\n",
       "      <td>0.353404</td>\n",
       "      <td>...</td>\n",
       "      <td>0.483320</td>\n",
       "      <td>0.360871</td>\n",
       "      <td>0.473832</td>\n",
       "      <td>0.640314</td>\n",
       "      <td>0.728877</td>\n",
       "      <td>0.187256</td>\n",
       "      <td>0.525381</td>\n",
       "      <td>0.570791</td>\n",
       "      <td>0.383951</td>\n",
       "      <td>0.349250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-21 17:00:00</th>\n",
       "      <td>0.432327</td>\n",
       "      <td>0.219004</td>\n",
       "      <td>0.492477</td>\n",
       "      <td>0.384737</td>\n",
       "      <td>0.669440</td>\n",
       "      <td>0.598877</td>\n",
       "      <td>0.556388</td>\n",
       "      <td>0.504110</td>\n",
       "      <td>0.565397</td>\n",
       "      <td>0.277792</td>\n",
       "      <td>...</td>\n",
       "      <td>0.352773</td>\n",
       "      <td>0.348645</td>\n",
       "      <td>0.427499</td>\n",
       "      <td>0.594911</td>\n",
       "      <td>0.698565</td>\n",
       "      <td>0.180463</td>\n",
       "      <td>0.486258</td>\n",
       "      <td>0.634140</td>\n",
       "      <td>0.430409</td>\n",
       "      <td>0.328985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-21 17:30:00</th>\n",
       "      <td>0.354311</td>\n",
       "      <td>0.210346</td>\n",
       "      <td>0.400935</td>\n",
       "      <td>0.314949</td>\n",
       "      <td>0.639246</td>\n",
       "      <td>0.546780</td>\n",
       "      <td>0.361477</td>\n",
       "      <td>0.404556</td>\n",
       "      <td>0.529910</td>\n",
       "      <td>0.221397</td>\n",
       "      <td>...</td>\n",
       "      <td>0.292393</td>\n",
       "      <td>0.300641</td>\n",
       "      <td>0.401178</td>\n",
       "      <td>0.522108</td>\n",
       "      <td>0.667534</td>\n",
       "      <td>0.149404</td>\n",
       "      <td>0.432749</td>\n",
       "      <td>0.587193</td>\n",
       "      <td>0.394299</td>\n",
       "      <td>0.299377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-21 18:00:00</th>\n",
       "      <td>0.327625</td>\n",
       "      <td>0.225696</td>\n",
       "      <td>0.376124</td>\n",
       "      <td>0.277541</td>\n",
       "      <td>0.592714</td>\n",
       "      <td>0.497159</td>\n",
       "      <td>0.338467</td>\n",
       "      <td>0.350176</td>\n",
       "      <td>0.524168</td>\n",
       "      <td>0.168671</td>\n",
       "      <td>...</td>\n",
       "      <td>0.267487</td>\n",
       "      <td>0.285378</td>\n",
       "      <td>0.404577</td>\n",
       "      <td>0.503769</td>\n",
       "      <td>0.651591</td>\n",
       "      <td>0.209528</td>\n",
       "      <td>0.417606</td>\n",
       "      <td>0.568981</td>\n",
       "      <td>0.332028</td>\n",
       "      <td>0.301424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-21 18:30:00</th>\n",
       "      <td>0.277184</td>\n",
       "      <td>0.245703</td>\n",
       "      <td>0.337465</td>\n",
       "      <td>0.254163</td>\n",
       "      <td>0.667740</td>\n",
       "      <td>0.478607</td>\n",
       "      <td>0.327931</td>\n",
       "      <td>0.322706</td>\n",
       "      <td>0.505169</td>\n",
       "      <td>0.175373</td>\n",
       "      <td>...</td>\n",
       "      <td>0.232975</td>\n",
       "      <td>0.268193</td>\n",
       "      <td>0.375837</td>\n",
       "      <td>0.449367</td>\n",
       "      <td>0.632869</td>\n",
       "      <td>0.249999</td>\n",
       "      <td>0.349022</td>\n",
       "      <td>0.545684</td>\n",
       "      <td>0.367284</td>\n",
       "      <td>0.270403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-22 09:30:00</th>\n",
       "      <td>0.471847</td>\n",
       "      <td>0.382561</td>\n",
       "      <td>0.208767</td>\n",
       "      <td>0.346169</td>\n",
       "      <td>0.157123</td>\n",
       "      <td>0.579645</td>\n",
       "      <td>0.254804</td>\n",
       "      <td>0.259584</td>\n",
       "      <td>0.416550</td>\n",
       "      <td>0.206068</td>\n",
       "      <td>...</td>\n",
       "      <td>0.298317</td>\n",
       "      <td>0.204017</td>\n",
       "      <td>0.409483</td>\n",
       "      <td>0.286495</td>\n",
       "      <td>0.344837</td>\n",
       "      <td>0.242820</td>\n",
       "      <td>0.237624</td>\n",
       "      <td>0.324621</td>\n",
       "      <td>0.444772</td>\n",
       "      <td>0.402463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-22 10:00:00</th>\n",
       "      <td>0.240212</td>\n",
       "      <td>0.281684</td>\n",
       "      <td>0.139550</td>\n",
       "      <td>0.162721</td>\n",
       "      <td>0.128547</td>\n",
       "      <td>0.254155</td>\n",
       "      <td>0.316357</td>\n",
       "      <td>0.206992</td>\n",
       "      <td>0.410344</td>\n",
       "      <td>0.197532</td>\n",
       "      <td>...</td>\n",
       "      <td>0.205824</td>\n",
       "      <td>0.182600</td>\n",
       "      <td>0.276008</td>\n",
       "      <td>0.164016</td>\n",
       "      <td>0.157692</td>\n",
       "      <td>0.245435</td>\n",
       "      <td>0.216112</td>\n",
       "      <td>0.310208</td>\n",
       "      <td>0.403293</td>\n",
       "      <td>0.310341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-22 10:30:00</th>\n",
       "      <td>0.190738</td>\n",
       "      <td>0.288075</td>\n",
       "      <td>0.118425</td>\n",
       "      <td>0.229427</td>\n",
       "      <td>0.138285</td>\n",
       "      <td>0.298170</td>\n",
       "      <td>0.306848</td>\n",
       "      <td>0.244316</td>\n",
       "      <td>0.384344</td>\n",
       "      <td>0.129891</td>\n",
       "      <td>...</td>\n",
       "      <td>0.156740</td>\n",
       "      <td>0.235796</td>\n",
       "      <td>0.278714</td>\n",
       "      <td>0.146649</td>\n",
       "      <td>0.139811</td>\n",
       "      <td>0.226134</td>\n",
       "      <td>0.146286</td>\n",
       "      <td>0.245713</td>\n",
       "      <td>0.284664</td>\n",
       "      <td>0.317894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-22 11:00:00</th>\n",
       "      <td>0.156867</td>\n",
       "      <td>0.247803</td>\n",
       "      <td>0.116203</td>\n",
       "      <td>0.093070</td>\n",
       "      <td>0.151848</td>\n",
       "      <td>0.131555</td>\n",
       "      <td>0.249039</td>\n",
       "      <td>0.395313</td>\n",
       "      <td>0.340444</td>\n",
       "      <td>0.103116</td>\n",
       "      <td>...</td>\n",
       "      <td>0.073557</td>\n",
       "      <td>0.219356</td>\n",
       "      <td>0.198852</td>\n",
       "      <td>0.119122</td>\n",
       "      <td>0.111400</td>\n",
       "      <td>0.211842</td>\n",
       "      <td>0.060303</td>\n",
       "      <td>0.121691</td>\n",
       "      <td>0.131160</td>\n",
       "      <td>0.354752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-22 11:30:00</th>\n",
       "      <td>0.117920</td>\n",
       "      <td>0.236391</td>\n",
       "      <td>0.062228</td>\n",
       "      <td>0.097277</td>\n",
       "      <td>0.110819</td>\n",
       "      <td>0.120787</td>\n",
       "      <td>0.321229</td>\n",
       "      <td>0.253058</td>\n",
       "      <td>0.308858</td>\n",
       "      <td>0.106870</td>\n",
       "      <td>...</td>\n",
       "      <td>0.079058</td>\n",
       "      <td>0.249409</td>\n",
       "      <td>0.160470</td>\n",
       "      <td>0.148938</td>\n",
       "      <td>0.099340</td>\n",
       "      <td>0.177279</td>\n",
       "      <td>0.062372</td>\n",
       "      <td>0.133324</td>\n",
       "      <td>0.176064</td>\n",
       "      <td>0.342403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-22 12:00:00</th>\n",
       "      <td>0.101493</td>\n",
       "      <td>0.270458</td>\n",
       "      <td>0.130093</td>\n",
       "      <td>0.118414</td>\n",
       "      <td>0.322923</td>\n",
       "      <td>0.206574</td>\n",
       "      <td>0.263500</td>\n",
       "      <td>0.240217</td>\n",
       "      <td>0.265336</td>\n",
       "      <td>0.083615</td>\n",
       "      <td>...</td>\n",
       "      <td>0.077838</td>\n",
       "      <td>0.203238</td>\n",
       "      <td>0.200103</td>\n",
       "      <td>0.109083</td>\n",
       "      <td>0.109312</td>\n",
       "      <td>0.278172</td>\n",
       "      <td>0.041093</td>\n",
       "      <td>0.148817</td>\n",
       "      <td>0.177243</td>\n",
       "      <td>0.330054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-22 12:30:00</th>\n",
       "      <td>0.125826</td>\n",
       "      <td>0.234036</td>\n",
       "      <td>0.087783</td>\n",
       "      <td>0.139552</td>\n",
       "      <td>0.247877</td>\n",
       "      <td>0.190646</td>\n",
       "      <td>0.274242</td>\n",
       "      <td>0.297197</td>\n",
       "      <td>0.209009</td>\n",
       "      <td>0.085427</td>\n",
       "      <td>...</td>\n",
       "      <td>0.070291</td>\n",
       "      <td>0.198404</td>\n",
       "      <td>0.167878</td>\n",
       "      <td>0.111722</td>\n",
       "      <td>0.092788</td>\n",
       "      <td>0.277739</td>\n",
       "      <td>0.045096</td>\n",
       "      <td>0.171585</td>\n",
       "      <td>0.213057</td>\n",
       "      <td>0.317706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-22 13:00:00</th>\n",
       "      <td>0.078169</td>\n",
       "      <td>0.215753</td>\n",
       "      <td>0.104974</td>\n",
       "      <td>0.160689</td>\n",
       "      <td>0.211875</td>\n",
       "      <td>0.146563</td>\n",
       "      <td>0.294073</td>\n",
       "      <td>0.214798</td>\n",
       "      <td>0.293634</td>\n",
       "      <td>0.089649</td>\n",
       "      <td>...</td>\n",
       "      <td>0.078142</td>\n",
       "      <td>0.209795</td>\n",
       "      <td>0.187622</td>\n",
       "      <td>0.121027</td>\n",
       "      <td>0.126770</td>\n",
       "      <td>0.213497</td>\n",
       "      <td>0.044573</td>\n",
       "      <td>0.167403</td>\n",
       "      <td>0.110933</td>\n",
       "      <td>0.377607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-22 13:30:00</th>\n",
       "      <td>0.108529</td>\n",
       "      <td>0.268844</td>\n",
       "      <td>0.136086</td>\n",
       "      <td>0.181826</td>\n",
       "      <td>0.278216</td>\n",
       "      <td>0.181819</td>\n",
       "      <td>0.314143</td>\n",
       "      <td>0.174125</td>\n",
       "      <td>0.315230</td>\n",
       "      <td>0.114295</td>\n",
       "      <td>...</td>\n",
       "      <td>0.079048</td>\n",
       "      <td>0.206493</td>\n",
       "      <td>0.194213</td>\n",
       "      <td>0.206135</td>\n",
       "      <td>0.115143</td>\n",
       "      <td>0.156697</td>\n",
       "      <td>0.101463</td>\n",
       "      <td>0.306418</td>\n",
       "      <td>0.151606</td>\n",
       "      <td>0.300399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-22 14:00:00</th>\n",
       "      <td>0.132704</td>\n",
       "      <td>0.264259</td>\n",
       "      <td>0.148662</td>\n",
       "      <td>0.202963</td>\n",
       "      <td>0.272539</td>\n",
       "      <td>0.380634</td>\n",
       "      <td>0.308126</td>\n",
       "      <td>0.148341</td>\n",
       "      <td>0.207452</td>\n",
       "      <td>0.105815</td>\n",
       "      <td>...</td>\n",
       "      <td>0.139854</td>\n",
       "      <td>0.193122</td>\n",
       "      <td>0.193924</td>\n",
       "      <td>0.235135</td>\n",
       "      <td>0.147377</td>\n",
       "      <td>0.194451</td>\n",
       "      <td>0.196577</td>\n",
       "      <td>0.231845</td>\n",
       "      <td>0.100511</td>\n",
       "      <td>0.266794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-22 14:30:00</th>\n",
       "      <td>0.147792</td>\n",
       "      <td>0.268457</td>\n",
       "      <td>0.096696</td>\n",
       "      <td>0.298974</td>\n",
       "      <td>0.219569</td>\n",
       "      <td>0.339018</td>\n",
       "      <td>0.235553</td>\n",
       "      <td>0.162894</td>\n",
       "      <td>0.175801</td>\n",
       "      <td>0.079371</td>\n",
       "      <td>...</td>\n",
       "      <td>0.113544</td>\n",
       "      <td>0.263837</td>\n",
       "      <td>0.193636</td>\n",
       "      <td>0.226685</td>\n",
       "      <td>0.118764</td>\n",
       "      <td>0.195719</td>\n",
       "      <td>0.155485</td>\n",
       "      <td>0.230212</td>\n",
       "      <td>0.153372</td>\n",
       "      <td>0.281711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-22 15:00:00</th>\n",
       "      <td>0.107605</td>\n",
       "      <td>0.206562</td>\n",
       "      <td>0.082443</td>\n",
       "      <td>0.216872</td>\n",
       "      <td>0.190245</td>\n",
       "      <td>0.220951</td>\n",
       "      <td>0.283191</td>\n",
       "      <td>0.212829</td>\n",
       "      <td>0.188130</td>\n",
       "      <td>0.128718</td>\n",
       "      <td>...</td>\n",
       "      <td>0.126848</td>\n",
       "      <td>0.283734</td>\n",
       "      <td>0.152900</td>\n",
       "      <td>0.232888</td>\n",
       "      <td>0.161178</td>\n",
       "      <td>0.242470</td>\n",
       "      <td>0.131862</td>\n",
       "      <td>0.170811</td>\n",
       "      <td>0.106054</td>\n",
       "      <td>0.247740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-22 15:30:00</th>\n",
       "      <td>0.116417</td>\n",
       "      <td>0.208148</td>\n",
       "      <td>0.072286</td>\n",
       "      <td>0.221240</td>\n",
       "      <td>0.231359</td>\n",
       "      <td>0.275541</td>\n",
       "      <td>0.227266</td>\n",
       "      <td>0.205306</td>\n",
       "      <td>0.188775</td>\n",
       "      <td>0.096286</td>\n",
       "      <td>...</td>\n",
       "      <td>0.105528</td>\n",
       "      <td>0.264841</td>\n",
       "      <td>0.210847</td>\n",
       "      <td>0.246725</td>\n",
       "      <td>0.143111</td>\n",
       "      <td>0.148726</td>\n",
       "      <td>0.109640</td>\n",
       "      <td>0.207628</td>\n",
       "      <td>0.090941</td>\n",
       "      <td>0.242459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-22 16:00:00</th>\n",
       "      <td>0.328109</td>\n",
       "      <td>0.280139</td>\n",
       "      <td>0.415009</td>\n",
       "      <td>0.552185</td>\n",
       "      <td>0.533258</td>\n",
       "      <td>0.470961</td>\n",
       "      <td>0.451655</td>\n",
       "      <td>0.496095</td>\n",
       "      <td>0.320705</td>\n",
       "      <td>0.182280</td>\n",
       "      <td>...</td>\n",
       "      <td>0.477698</td>\n",
       "      <td>0.309128</td>\n",
       "      <td>0.504136</td>\n",
       "      <td>0.476747</td>\n",
       "      <td>0.498030</td>\n",
       "      <td>0.242144</td>\n",
       "      <td>0.263757</td>\n",
       "      <td>0.335148</td>\n",
       "      <td>0.268405</td>\n",
       "      <td>0.353340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-22 16:30:00</th>\n",
       "      <td>0.403620</td>\n",
       "      <td>0.218296</td>\n",
       "      <td>0.501977</td>\n",
       "      <td>0.439286</td>\n",
       "      <td>0.723990</td>\n",
       "      <td>0.570556</td>\n",
       "      <td>0.600590</td>\n",
       "      <td>0.509930</td>\n",
       "      <td>0.504594</td>\n",
       "      <td>0.312294</td>\n",
       "      <td>...</td>\n",
       "      <td>0.351593</td>\n",
       "      <td>0.310643</td>\n",
       "      <td>0.476657</td>\n",
       "      <td>0.565970</td>\n",
       "      <td>0.655900</td>\n",
       "      <td>0.175729</td>\n",
       "      <td>0.451680</td>\n",
       "      <td>0.567584</td>\n",
       "      <td>0.315340</td>\n",
       "      <td>0.346353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-22 17:00:00</th>\n",
       "      <td>0.362888</td>\n",
       "      <td>0.214970</td>\n",
       "      <td>0.369042</td>\n",
       "      <td>0.399727</td>\n",
       "      <td>0.704322</td>\n",
       "      <td>0.476544</td>\n",
       "      <td>0.537281</td>\n",
       "      <td>0.412729</td>\n",
       "      <td>0.574329</td>\n",
       "      <td>0.273010</td>\n",
       "      <td>...</td>\n",
       "      <td>0.287178</td>\n",
       "      <td>0.300417</td>\n",
       "      <td>0.413235</td>\n",
       "      <td>0.539873</td>\n",
       "      <td>0.647335</td>\n",
       "      <td>0.182891</td>\n",
       "      <td>0.405390</td>\n",
       "      <td>0.583944</td>\n",
       "      <td>0.331202</td>\n",
       "      <td>0.303184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-22 17:30:00</th>\n",
       "      <td>0.372327</td>\n",
       "      <td>0.198227</td>\n",
       "      <td>0.358524</td>\n",
       "      <td>0.371859</td>\n",
       "      <td>0.701889</td>\n",
       "      <td>0.423160</td>\n",
       "      <td>0.561012</td>\n",
       "      <td>0.328320</td>\n",
       "      <td>0.541719</td>\n",
       "      <td>0.232622</td>\n",
       "      <td>...</td>\n",
       "      <td>0.539427</td>\n",
       "      <td>0.318216</td>\n",
       "      <td>0.420371</td>\n",
       "      <td>0.511979</td>\n",
       "      <td>0.634456</td>\n",
       "      <td>0.167874</td>\n",
       "      <td>0.366078</td>\n",
       "      <td>0.564211</td>\n",
       "      <td>0.332724</td>\n",
       "      <td>0.360923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-22 18:00:00</th>\n",
       "      <td>0.390475</td>\n",
       "      <td>0.185720</td>\n",
       "      <td>0.275536</td>\n",
       "      <td>0.357817</td>\n",
       "      <td>0.663730</td>\n",
       "      <td>0.409181</td>\n",
       "      <td>0.429965</td>\n",
       "      <td>0.294807</td>\n",
       "      <td>0.516002</td>\n",
       "      <td>0.224542</td>\n",
       "      <td>...</td>\n",
       "      <td>0.511192</td>\n",
       "      <td>0.277462</td>\n",
       "      <td>0.379179</td>\n",
       "      <td>0.469562</td>\n",
       "      <td>0.612448</td>\n",
       "      <td>0.163187</td>\n",
       "      <td>0.348213</td>\n",
       "      <td>0.518803</td>\n",
       "      <td>0.291524</td>\n",
       "      <td>0.356377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-22 18:30:00</th>\n",
       "      <td>0.357322</td>\n",
       "      <td>0.186599</td>\n",
       "      <td>0.299702</td>\n",
       "      <td>0.420834</td>\n",
       "      <td>0.651291</td>\n",
       "      <td>0.350701</td>\n",
       "      <td>0.354919</td>\n",
       "      <td>0.275624</td>\n",
       "      <td>0.484238</td>\n",
       "      <td>0.230405</td>\n",
       "      <td>...</td>\n",
       "      <td>0.438785</td>\n",
       "      <td>0.273800</td>\n",
       "      <td>0.382256</td>\n",
       "      <td>0.451034</td>\n",
       "      <td>0.603145</td>\n",
       "      <td>0.131032</td>\n",
       "      <td>0.326006</td>\n",
       "      <td>0.509935</td>\n",
       "      <td>0.339706</td>\n",
       "      <td>0.332500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>760 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "CAMERA_ID                 4         5         6         7         8    \\\n",
       "TIMESTAMP                                                               \n",
       "2010-10-11 09:30:00  0.832721  0.736465  0.673375  0.875612  1.000000   \n",
       "2010-10-11 10:00:00  0.717267  0.677046  0.539202  0.536337  0.928692   \n",
       "2010-10-11 10:30:00  0.613608  0.580922  0.429255  0.479447  0.857383   \n",
       "2010-10-11 11:00:00  0.418400  0.434257  0.266390  0.339875  0.725234   \n",
       "2010-10-11 11:30:00  0.361012  0.404033  0.204576  0.306596  0.321575   \n",
       "2010-10-11 12:00:00  0.304653  0.428367  0.183852  0.274417  0.289617   \n",
       "2010-10-11 12:30:00  0.311956  0.304918  0.206830  0.266901  0.291421   \n",
       "2010-10-11 13:00:00  0.333483  0.316085  0.242929  0.242035  0.285842   \n",
       "2010-10-11 13:30:00  0.285591  0.366087  0.161221  0.244930  0.305829   \n",
       "2010-10-11 14:00:00  0.270771  0.277595  0.120844  0.226747  0.304305   \n",
       "2010-10-11 14:30:00  0.341074  0.261700  0.137740  0.218907  0.317512   \n",
       "2010-10-11 15:00:00  0.340054  0.229100  0.138745  0.260715  0.348867   \n",
       "2010-10-11 15:30:00  0.423740  0.220598  0.203397  0.377745  0.419855   \n",
       "2010-10-11 16:00:00  0.446975  0.241334  0.160889  0.402249  0.513418   \n",
       "2010-10-11 16:30:00  0.541662  0.373131  0.179553  0.452027  0.634326   \n",
       "2010-10-11 17:00:00  0.623828  0.570275  0.421990  0.577903  0.686852   \n",
       "2010-10-11 17:30:00  0.560180  0.649326  0.449701  0.601893  0.650849   \n",
       "2010-10-11 18:00:00  0.479465  0.583546  0.507219  0.368292  0.548068   \n",
       "2010-10-11 18:30:00  0.628765  0.642776  0.650817  0.734953  0.703240   \n",
       "2010-10-12 09:30:00  0.406132  0.432930  0.527475  0.311408  0.440725   \n",
       "2010-10-12 10:00:00  0.394718  0.422405  0.492325  0.321751  0.387691   \n",
       "2010-10-12 10:30:00  0.392652  0.406920  0.370317  0.259585  0.292303   \n",
       "2010-10-12 11:00:00  0.350642  0.374163  0.342122  0.231752  0.261941   \n",
       "2010-10-12 11:30:00  0.377405  0.408138  0.316887  0.222012  0.282189   \n",
       "2010-10-12 12:00:00  0.329586  0.327265  0.299036  0.263719  0.256575   \n",
       "2010-10-12 12:30:00  0.283286  0.299494  0.354648  0.235572  0.246865   \n",
       "2010-10-12 13:00:00  0.267242  0.295020  0.316561  0.288581  0.269757   \n",
       "2010-10-12 13:30:00  0.223575  0.271862  0.322887  0.327436  0.297633   \n",
       "2010-10-12 14:00:00  0.185948  0.245146  0.319398  0.343789  0.259786   \n",
       "2010-10-12 14:30:00  0.181039  0.239531  0.266494  0.309499  0.328422   \n",
       "...                       ...       ...       ...       ...       ...   \n",
       "2010-11-21 13:30:00  0.113510  0.230744  0.109129  0.061064  0.079682   \n",
       "2010-11-21 14:00:00  0.156925  0.237202  0.288286  0.073161  0.080484   \n",
       "2010-11-21 14:30:00  0.067753  0.219193  0.094437  0.070939  0.168746   \n",
       "2010-11-21 15:00:00  0.068327  0.203660  0.091436  0.062752  0.126965   \n",
       "2010-11-21 15:30:00  0.092746  0.214257  0.125261  0.092806  0.169692   \n",
       "2010-11-21 16:00:00  0.286689  0.291706  0.427269  0.530477  0.516520   \n",
       "2010-11-21 16:30:00  0.466970  0.267430  0.619214  0.550645  0.730653   \n",
       "2010-11-21 17:00:00  0.432327  0.219004  0.492477  0.384737  0.669440   \n",
       "2010-11-21 17:30:00  0.354311  0.210346  0.400935  0.314949  0.639246   \n",
       "2010-11-21 18:00:00  0.327625  0.225696  0.376124  0.277541  0.592714   \n",
       "2010-11-21 18:30:00  0.277184  0.245703  0.337465  0.254163  0.667740   \n",
       "2010-11-22 09:30:00  0.471847  0.382561  0.208767  0.346169  0.157123   \n",
       "2010-11-22 10:00:00  0.240212  0.281684  0.139550  0.162721  0.128547   \n",
       "2010-11-22 10:30:00  0.190738  0.288075  0.118425  0.229427  0.138285   \n",
       "2010-11-22 11:00:00  0.156867  0.247803  0.116203  0.093070  0.151848   \n",
       "2010-11-22 11:30:00  0.117920  0.236391  0.062228  0.097277  0.110819   \n",
       "2010-11-22 12:00:00  0.101493  0.270458  0.130093  0.118414  0.322923   \n",
       "2010-11-22 12:30:00  0.125826  0.234036  0.087783  0.139552  0.247877   \n",
       "2010-11-22 13:00:00  0.078169  0.215753  0.104974  0.160689  0.211875   \n",
       "2010-11-22 13:30:00  0.108529  0.268844  0.136086  0.181826  0.278216   \n",
       "2010-11-22 14:00:00  0.132704  0.264259  0.148662  0.202963  0.272539   \n",
       "2010-11-22 14:30:00  0.147792  0.268457  0.096696  0.298974  0.219569   \n",
       "2010-11-22 15:00:00  0.107605  0.206562  0.082443  0.216872  0.190245   \n",
       "2010-11-22 15:30:00  0.116417  0.208148  0.072286  0.221240  0.231359   \n",
       "2010-11-22 16:00:00  0.328109  0.280139  0.415009  0.552185  0.533258   \n",
       "2010-11-22 16:30:00  0.403620  0.218296  0.501977  0.439286  0.723990   \n",
       "2010-11-22 17:00:00  0.362888  0.214970  0.369042  0.399727  0.704322   \n",
       "2010-11-22 17:30:00  0.372327  0.198227  0.358524  0.371859  0.701889   \n",
       "2010-11-22 18:00:00  0.390475  0.185720  0.275536  0.357817  0.663730   \n",
       "2010-11-22 18:30:00  0.357322  0.186599  0.299702  0.420834  0.651291   \n",
       "\n",
       "CAMERA_ID                 9         15        20        26        30   ...  \\\n",
       "TIMESTAMP                                                              ...   \n",
       "2010-10-11 09:30:00  0.722307  0.757152  0.680594  0.665648  0.684109  ...   \n",
       "2010-10-11 10:00:00  0.588867  0.552925  0.475241  0.500489  0.403454  ...   \n",
       "2010-10-11 10:30:00  0.536391  0.478475  0.367212  0.572155  0.488556  ...   \n",
       "2010-10-11 11:00:00  0.430256  0.267442  0.182961  0.365195  0.352724  ...   \n",
       "2010-10-11 11:30:00  0.389043  0.256184  0.179937  0.287719  0.352193  ...   \n",
       "2010-10-11 12:00:00  0.390220  0.238520  0.251622  0.230938  0.302200  ...   \n",
       "2010-10-11 12:30:00  0.414603  0.269281  0.253575  0.284814  0.249794  ...   \n",
       "2010-10-11 13:00:00  0.357791  0.320907  0.263375  0.325637  0.223476  ...   \n",
       "2010-10-11 13:30:00  0.303704  0.377544  0.264186  0.344778  0.177547  ...   \n",
       "2010-10-11 14:00:00  0.256422  0.342459  0.238910  0.360085  0.181137  ...   \n",
       "2010-10-11 14:30:00  0.353358  0.300350  0.246336  0.385627  0.205027  ...   \n",
       "2010-10-11 15:00:00  0.419101  0.346580  0.291746  0.423853  0.268816  ...   \n",
       "2010-10-11 15:30:00  0.562095  0.361028  0.377177  0.414986  0.305366  ...   \n",
       "2010-10-11 16:00:00  0.522618  0.454824  0.404235  0.399235  0.299559  ...   \n",
       "2010-10-11 16:30:00  0.523552  0.572142  0.415623  0.422166  0.342624  ...   \n",
       "2010-10-11 17:00:00  0.536800  0.703394  0.413542  0.478655  0.372564  ...   \n",
       "2010-10-11 17:30:00  0.549598  0.656522  0.457139  0.607575  0.329682  ...   \n",
       "2010-10-11 18:00:00  0.559417  0.439797  0.442055  0.490930  0.256381  ...   \n",
       "2010-10-11 18:30:00  0.727471  0.754835  0.650868  0.681445  0.484290  ...   \n",
       "2010-10-12 09:30:00  0.481055  0.682421  0.364472  0.554761  0.393615  ...   \n",
       "2010-10-12 10:00:00  0.502979  0.651874  0.366705  0.442578  0.371921  ...   \n",
       "2010-10-12 10:30:00  0.439099  0.369541  0.317714  0.378675  0.311229  ...   \n",
       "2010-10-12 11:00:00  0.431046  0.256147  0.263220  0.268949  0.263107  ...   \n",
       "2010-10-12 11:30:00  0.430658  0.234854  0.192700  0.231466  0.235408  ...   \n",
       "2010-10-12 12:00:00  0.383583  0.237543  0.195561  0.218082  0.214458  ...   \n",
       "2010-10-12 12:30:00  0.374685  0.375374  0.304679  0.334134  0.199777  ...   \n",
       "2010-10-12 13:00:00  0.344458  0.441813  0.427538  0.396001  0.223278  ...   \n",
       "2010-10-12 13:30:00  0.287486  0.453984  0.309188  0.429086  0.199601  ...   \n",
       "2010-10-12 14:00:00  0.311129  0.488415  0.301947  0.465054  0.192551  ...   \n",
       "2010-10-12 14:30:00  0.335283  0.470166  0.311311  0.461646  0.190035  ...   \n",
       "...                       ...       ...       ...       ...       ...  ...   \n",
       "2010-11-21 13:30:00  0.091333  0.153531  0.206270  0.086193  0.037398  ...   \n",
       "2010-11-21 14:00:00  0.097429  0.128835  0.200623  0.089523  0.051702  ...   \n",
       "2010-11-21 14:30:00  0.126417  0.108765  0.229881  0.074526  0.049713  ...   \n",
       "2010-11-21 15:00:00  0.187496  0.089046  0.188985  0.075719  0.043633  ...   \n",
       "2010-11-21 15:30:00  0.185095  0.165188  0.175775  0.113867  0.118803  ...   \n",
       "2010-11-21 16:00:00  0.373795  0.438778  0.540753  0.405293  0.244701  ...   \n",
       "2010-11-21 16:30:00  0.681642  0.662437  0.580334  0.556491  0.353404  ...   \n",
       "2010-11-21 17:00:00  0.598877  0.556388  0.504110  0.565397  0.277792  ...   \n",
       "2010-11-21 17:30:00  0.546780  0.361477  0.404556  0.529910  0.221397  ...   \n",
       "2010-11-21 18:00:00  0.497159  0.338467  0.350176  0.524168  0.168671  ...   \n",
       "2010-11-21 18:30:00  0.478607  0.327931  0.322706  0.505169  0.175373  ...   \n",
       "2010-11-22 09:30:00  0.579645  0.254804  0.259584  0.416550  0.206068  ...   \n",
       "2010-11-22 10:00:00  0.254155  0.316357  0.206992  0.410344  0.197532  ...   \n",
       "2010-11-22 10:30:00  0.298170  0.306848  0.244316  0.384344  0.129891  ...   \n",
       "2010-11-22 11:00:00  0.131555  0.249039  0.395313  0.340444  0.103116  ...   \n",
       "2010-11-22 11:30:00  0.120787  0.321229  0.253058  0.308858  0.106870  ...   \n",
       "2010-11-22 12:00:00  0.206574  0.263500  0.240217  0.265336  0.083615  ...   \n",
       "2010-11-22 12:30:00  0.190646  0.274242  0.297197  0.209009  0.085427  ...   \n",
       "2010-11-22 13:00:00  0.146563  0.294073  0.214798  0.293634  0.089649  ...   \n",
       "2010-11-22 13:30:00  0.181819  0.314143  0.174125  0.315230  0.114295  ...   \n",
       "2010-11-22 14:00:00  0.380634  0.308126  0.148341  0.207452  0.105815  ...   \n",
       "2010-11-22 14:30:00  0.339018  0.235553  0.162894  0.175801  0.079371  ...   \n",
       "2010-11-22 15:00:00  0.220951  0.283191  0.212829  0.188130  0.128718  ...   \n",
       "2010-11-22 15:30:00  0.275541  0.227266  0.205306  0.188775  0.096286  ...   \n",
       "2010-11-22 16:00:00  0.470961  0.451655  0.496095  0.320705  0.182280  ...   \n",
       "2010-11-22 16:30:00  0.570556  0.600590  0.509930  0.504594  0.312294  ...   \n",
       "2010-11-22 17:00:00  0.476544  0.537281  0.412729  0.574329  0.273010  ...   \n",
       "2010-11-22 17:30:00  0.423160  0.561012  0.328320  0.541719  0.232622  ...   \n",
       "2010-11-22 18:00:00  0.409181  0.429965  0.294807  0.516002  0.224542  ...   \n",
       "2010-11-22 18:30:00  0.350701  0.354919  0.275624  0.484238  0.230405  ...   \n",
       "\n",
       "CAMERA_ID                 98        101       103       107       108  \\\n",
       "TIMESTAMP                                                               \n",
       "2010-10-11 09:30:00  0.829776  0.784347  0.683784  0.690634  0.841041   \n",
       "2010-10-11 10:00:00  0.758407  0.623102  0.457033  0.578736  0.778317   \n",
       "2010-10-11 10:30:00  0.763662  0.777090  0.536671  0.652575  0.764758   \n",
       "2010-10-11 11:00:00  0.622577  0.653502  0.499189  0.514473  0.577114   \n",
       "2010-10-11 11:30:00  0.551073  0.404707  0.391159  0.448867  0.491578   \n",
       "2010-10-11 12:00:00  0.400982  0.298795  0.360811  0.400292  0.475637   \n",
       "2010-10-11 12:30:00  0.373132  0.264625  0.333265  0.376261  0.433424   \n",
       "2010-10-11 13:00:00  0.487796  0.283220  0.318404  0.454659  0.450762   \n",
       "2010-10-11 13:30:00  0.508135  0.304850  0.298616  0.483756  0.410347   \n",
       "2010-10-11 14:00:00  0.555788  0.290470  0.261859  0.368063  0.380744   \n",
       "2010-10-11 14:30:00  0.572042  0.275689  0.261115  0.322878  0.380237   \n",
       "2010-10-11 15:00:00  0.542959  0.298133  0.317831  0.293275  0.409033   \n",
       "2010-10-11 15:30:00  0.476663  0.397092  0.522405  0.322164  0.479857   \n",
       "2010-10-11 16:00:00  0.419207  0.471665  0.529905  0.343290  0.579164   \n",
       "2010-10-11 16:30:00  0.371676  0.551738  0.529345  0.464809  0.662418   \n",
       "2010-10-11 17:00:00  0.386228  0.538251  0.473158  0.544584  0.700178   \n",
       "2010-10-11 17:30:00  0.414344  0.647150  0.440155  0.634593  0.733539   \n",
       "2010-10-11 18:00:00  0.396956  0.603948  0.458544  0.443475  0.679777   \n",
       "2010-10-11 18:30:00  0.689894  0.688225  0.828009  0.734000  0.794301   \n",
       "2010-10-12 09:30:00  0.553459  0.621870  0.661458  0.313904  0.539148   \n",
       "2010-10-12 10:00:00  0.535841  0.594163  0.652359  0.291397  0.455822   \n",
       "2010-10-12 10:30:00  0.449602  0.569645  0.616223  0.257318  0.410808   \n",
       "2010-10-12 11:00:00  0.388755  0.521915  0.619089  0.293859  0.463861   \n",
       "2010-10-12 11:30:00  0.382010  0.527725  0.808275  0.271848  0.486010   \n",
       "2010-10-12 12:00:00  0.402677  0.489514  0.742377  0.256742  0.454464   \n",
       "2010-10-12 12:30:00  0.432488  0.354795  0.535441  0.253927  0.410649   \n",
       "2010-10-12 13:00:00  0.458570  0.352001  0.484725  0.253990  0.445762   \n",
       "2010-10-12 13:30:00  0.488456  0.294045  0.448668  0.359512  0.410957   \n",
       "2010-10-12 14:00:00  0.507368  0.246207  0.433282  0.292105  0.458807   \n",
       "2010-10-12 14:30:00  0.469791  0.331082  0.419413  0.306579  0.427612   \n",
       "...                       ...       ...       ...       ...       ...   \n",
       "2010-11-21 13:30:00  0.110223  0.264634  0.199198  0.189720  0.111470   \n",
       "2010-11-21 14:00:00  0.111614  0.273451  0.191858  0.146628  0.119255   \n",
       "2010-11-21 14:30:00  0.091772  0.291459  0.166140  0.146256  0.111709   \n",
       "2010-11-21 15:00:00  0.095344  0.264108  0.160452  0.141558  0.130020   \n",
       "2010-11-21 15:30:00  0.102777  0.284151  0.233905  0.166304  0.118396   \n",
       "2010-11-21 16:00:00  0.411930  0.346484  0.564950  0.303317  0.396241   \n",
       "2010-11-21 16:30:00  0.483320  0.360871  0.473832  0.640314  0.728877   \n",
       "2010-11-21 17:00:00  0.352773  0.348645  0.427499  0.594911  0.698565   \n",
       "2010-11-21 17:30:00  0.292393  0.300641  0.401178  0.522108  0.667534   \n",
       "2010-11-21 18:00:00  0.267487  0.285378  0.404577  0.503769  0.651591   \n",
       "2010-11-21 18:30:00  0.232975  0.268193  0.375837  0.449367  0.632869   \n",
       "2010-11-22 09:30:00  0.298317  0.204017  0.409483  0.286495  0.344837   \n",
       "2010-11-22 10:00:00  0.205824  0.182600  0.276008  0.164016  0.157692   \n",
       "2010-11-22 10:30:00  0.156740  0.235796  0.278714  0.146649  0.139811   \n",
       "2010-11-22 11:00:00  0.073557  0.219356  0.198852  0.119122  0.111400   \n",
       "2010-11-22 11:30:00  0.079058  0.249409  0.160470  0.148938  0.099340   \n",
       "2010-11-22 12:00:00  0.077838  0.203238  0.200103  0.109083  0.109312   \n",
       "2010-11-22 12:30:00  0.070291  0.198404  0.167878  0.111722  0.092788   \n",
       "2010-11-22 13:00:00  0.078142  0.209795  0.187622  0.121027  0.126770   \n",
       "2010-11-22 13:30:00  0.079048  0.206493  0.194213  0.206135  0.115143   \n",
       "2010-11-22 14:00:00  0.139854  0.193122  0.193924  0.235135  0.147377   \n",
       "2010-11-22 14:30:00  0.113544  0.263837  0.193636  0.226685  0.118764   \n",
       "2010-11-22 15:00:00  0.126848  0.283734  0.152900  0.232888  0.161178   \n",
       "2010-11-22 15:30:00  0.105528  0.264841  0.210847  0.246725  0.143111   \n",
       "2010-11-22 16:00:00  0.477698  0.309128  0.504136  0.476747  0.498030   \n",
       "2010-11-22 16:30:00  0.351593  0.310643  0.476657  0.565970  0.655900   \n",
       "2010-11-22 17:00:00  0.287178  0.300417  0.413235  0.539873  0.647335   \n",
       "2010-11-22 17:30:00  0.539427  0.318216  0.420371  0.511979  0.634456   \n",
       "2010-11-22 18:00:00  0.511192  0.277462  0.379179  0.469562  0.612448   \n",
       "2010-11-22 18:30:00  0.438785  0.273800  0.382256  0.451034  0.603145   \n",
       "\n",
       "CAMERA_ID                 111       117       118       119       120  \n",
       "TIMESTAMP                                                              \n",
       "2010-10-11 09:30:00  0.767792  0.692569  0.767109  0.918728  0.862367  \n",
       "2010-10-11 10:00:00  0.819475  0.549714  0.579417  0.716728  0.710952  \n",
       "2010-10-11 10:30:00  0.828405  0.575197  0.616658  0.675727  0.736828  \n",
       "2010-10-11 11:00:00  0.595619  0.433528  0.578645  0.592677  0.620731  \n",
       "2010-10-11 11:30:00  0.472831  0.432047  0.497837  0.537321  0.566835  \n",
       "2010-10-11 12:00:00  0.434021  0.443339  0.384552  0.416145  0.502617  \n",
       "2010-10-11 12:30:00  0.433238  0.462217  0.432484  0.382512  0.483837  \n",
       "2010-10-11 13:00:00  0.426478  0.391113  0.390846  0.378882  0.507946  \n",
       "2010-10-11 13:30:00  0.475361  0.333088  0.451806  0.526446  0.457300  \n",
       "2010-10-11 14:00:00  0.423746  0.318768  0.446765  0.521514  0.436164  \n",
       "2010-10-11 14:30:00  0.402009  0.289831  0.438747  0.325464  0.421445  \n",
       "2010-10-11 15:00:00  0.433741  0.354654  0.454054  0.275597  0.513977  \n",
       "2010-10-11 15:30:00  0.409845  0.377025  0.538367  0.305541  0.673131  \n",
       "2010-10-11 16:00:00  0.422125  0.359624  0.519280  0.303601  0.707524  \n",
       "2010-10-11 16:30:00  0.589568  0.444026  0.535060  0.441724  0.499553  \n",
       "2010-10-11 17:00:00  0.691329  0.507410  0.580030  0.626056  0.394785  \n",
       "2010-10-11 17:30:00  0.642168  0.563282  0.593026  0.646877  0.369479  \n",
       "2010-10-11 18:00:00  0.548853  0.442438  0.540490  0.440417  0.400268  \n",
       "2010-10-11 18:30:00  0.629404  0.657569  0.623442  0.525996  0.667932  \n",
       "2010-10-12 09:30:00  0.537466  0.348860  0.388840  0.356299  0.392526  \n",
       "2010-10-12 10:00:00  0.614017  0.305964  0.339388  0.313437  0.357183  \n",
       "2010-10-12 10:30:00  0.594062  0.207295  0.316366  0.302657  0.356199  \n",
       "2010-10-12 11:00:00  0.551128  0.177354  0.404294  0.243649  0.367306  \n",
       "2010-10-12 11:30:00  0.563133  0.208546  0.355715  0.219783  0.520785  \n",
       "2010-10-12 12:00:00  0.527450  0.177078  0.309275  0.216600  0.511947  \n",
       "2010-10-12 12:30:00  0.477343  0.140617  0.308512  0.172058  0.501595  \n",
       "2010-10-12 13:00:00  0.495733  0.172163  0.306449  0.178023  0.474232  \n",
       "2010-10-12 13:30:00  0.458989  0.172077  0.272916  0.261179  0.445273  \n",
       "2010-10-12 14:00:00  0.440723  0.212970  0.304422  0.225522  0.448808  \n",
       "2010-10-12 14:30:00  0.431576  0.241121  0.293958  0.144914  0.470750  \n",
       "...                       ...       ...       ...       ...       ...  \n",
       "2010-11-21 13:30:00  0.181396  0.070860  0.172657  0.087835  0.224782  \n",
       "2010-11-21 14:00:00  0.172107  0.109352  0.119709  0.099634  0.245257  \n",
       "2010-11-21 14:30:00  0.188251  0.045930  0.117796  0.114633  0.199181  \n",
       "2010-11-21 15:00:00  0.179787  0.114821  0.152087  0.126461  0.225532  \n",
       "2010-11-21 15:30:00  0.154542  0.084295  0.135187  0.095699  0.249253  \n",
       "2010-11-21 16:00:00  0.255057  0.185105  0.259899  0.169617  0.386337  \n",
       "2010-11-21 16:30:00  0.187256  0.525381  0.570791  0.383951  0.349250  \n",
       "2010-11-21 17:00:00  0.180463  0.486258  0.634140  0.430409  0.328985  \n",
       "2010-11-21 17:30:00  0.149404  0.432749  0.587193  0.394299  0.299377  \n",
       "2010-11-21 18:00:00  0.209528  0.417606  0.568981  0.332028  0.301424  \n",
       "2010-11-21 18:30:00  0.249999  0.349022  0.545684  0.367284  0.270403  \n",
       "2010-11-22 09:30:00  0.242820  0.237624  0.324621  0.444772  0.402463  \n",
       "2010-11-22 10:00:00  0.245435  0.216112  0.310208  0.403293  0.310341  \n",
       "2010-11-22 10:30:00  0.226134  0.146286  0.245713  0.284664  0.317894  \n",
       "2010-11-22 11:00:00  0.211842  0.060303  0.121691  0.131160  0.354752  \n",
       "2010-11-22 11:30:00  0.177279  0.062372  0.133324  0.176064  0.342403  \n",
       "2010-11-22 12:00:00  0.278172  0.041093  0.148817  0.177243  0.330054  \n",
       "2010-11-22 12:30:00  0.277739  0.045096  0.171585  0.213057  0.317706  \n",
       "2010-11-22 13:00:00  0.213497  0.044573  0.167403  0.110933  0.377607  \n",
       "2010-11-22 13:30:00  0.156697  0.101463  0.306418  0.151606  0.300399  \n",
       "2010-11-22 14:00:00  0.194451  0.196577  0.231845  0.100511  0.266794  \n",
       "2010-11-22 14:30:00  0.195719  0.155485  0.230212  0.153372  0.281711  \n",
       "2010-11-22 15:00:00  0.242470  0.131862  0.170811  0.106054  0.247740  \n",
       "2010-11-22 15:30:00  0.148726  0.109640  0.207628  0.090941  0.242459  \n",
       "2010-11-22 16:00:00  0.242144  0.263757  0.335148  0.268405  0.353340  \n",
       "2010-11-22 16:30:00  0.175729  0.451680  0.567584  0.315340  0.346353  \n",
       "2010-11-22 17:00:00  0.182891  0.405390  0.583944  0.331202  0.303184  \n",
       "2010-11-22 17:30:00  0.167874  0.366078  0.564211  0.332724  0.360923  \n",
       "2010-11-22 18:00:00  0.163187  0.348213  0.518803  0.291524  0.356377  \n",
       "2010-11-22 18:30:00  0.131032  0.326006  0.509935  0.339706  0.332500  \n",
       "\n",
       "[760 rows x 58 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-24T19:49:37.254529Z",
     "start_time": "2019-05-24T19:49:37.238876Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras import Sequential\n",
    "from keras.layers import Dense, Activation, LSTM\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.optimizers import Adam, RMSprop, SGD\n",
    "from keras import regularizers\n",
    "\n",
    "from keras.layers import Input, Concatenate, Reshape, Lambda, Dropout\n",
    "from keras.layers import TimeDistributed, Bidirectional\n",
    "from keras.models import Model, load_model\n",
    "\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, CSVLogger #added csv logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-24T19:49:37.301410Z",
     "start_time": "2019-05-24T19:49:37.285801Z"
    }
   },
   "outputs": [],
   "source": [
    "TIMESTEPS = 19 * 7 #this should be played with to find a good one!\n",
    "CAMERA_FEATURES = 58 #this is all the cameras we have. We focus on one at a time in this part of the study.\n",
    "BATCH_SIZE = 1 #let's stick to STATEFUL RNN models with BATCH_SIZE of 1. We can try batch learning later but it kinda would be hard to implement the inference model (where it actually uses the model on incoming data to predict what happens next.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-24T20:27:56.111496Z",
     "start_time": "2019-05-24T20:27:56.095876Z"
    }
   },
   "outputs": [],
   "source": [
    "#df must be pivoted df not the original one.\n",
    "#TODO reimplement it for your understanding\n",
    "\n",
    "def get_data_generator(df, camera_id, TIMESTEPS, mode):\n",
    "    if mode == \"train\": \n",
    "        while True:\n",
    "            for i in range(0, L-TIMESTEPS): #first 3/4th of the time (30 days)\n",
    "                X = np.reshape(df.loc[:,camera_id].iloc[i:i+TIMESTEPS].values, newshape=(BATCH_SIZE,TIMESTEPS,1) ) # 1 is the number of features we have which is one cause for each camera we have have itself.\n",
    "                y = np.reshape(df.loc[:,camera_id].iloc[i+TIMESTEPS], newshape=(BATCH_SIZE,1)) #it is just one number but we reshape it as two dim tensor (1,1)\n",
    "                yield (X,y) #in generator must return a tuple of input and output in training mode.\n",
    "                \n",
    "    elif mode == \"eval\": \n",
    "        while True:\n",
    "            for i in range(L-TIMESTEPS, len(df) - TIMESTEPS): #remaining quarter of data (10 days)\n",
    "                X = np.reshape(df.loc[:,camera_id].iloc[i:i+TIMESTEPS].values, newshape=(BATCH_SIZE,TIMESTEPS,1) ) # 1 is the number of features we have which is one cause for each camera we have have itself.\n",
    "                y = np.reshape(df.loc[:,camera_id].iloc[i+TIMESTEPS], newshape=(BATCH_SIZE,1))\n",
    "                yield (X,y) #in generator must return a tuple of input and output in training mode.\n",
    "                \n",
    "    elif mode == \"predict\": \n",
    "        while True:\n",
    "            for i in range(L-TIMESTEPS, len(df) - TIMESTEPS): #same as eval without target y\n",
    "                yield np.reshape(df.loc[:,camera_id].iloc[i:i+TIMESTEPS].values, newshape=(BATCH_SIZE,TIMESTEPS,1) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-23T05:45:10.386437Z",
     "start_time": "2019-05-23T05:45:10.378439Z"
    }
   },
   "outputs": [],
   "source": [
    "#you can use my code here from the all cameras model I'm working on. \n",
    "#function returns layer objects you need to add to your model where you need an LSTM block.\n",
    "#It supports stacking up to 3 lstms and bidirectional lstm wrapper.\n",
    "#assuming the model = Sequential()\n",
    "#layers = get_lstm_layers(params)\n",
    "#for layer in layers:\n",
    "#    model.add(layer)\n",
    "def get_lstm_layers(params):\n",
    "    \"\"\"returns keras tensor output of a block of stateful lstms (potentially stacked).\"\"\"\n",
    "    n = params[\"stack_lstm_count\"]\n",
    "\n",
    "    layers = []\n",
    "    \n",
    "    lstm1 = LSTM( params[\"lstm1_units\"],\n",
    "                     #bii = (1,399,174)\n",
    "                     batch_input_shape=(1,params[\"timesteps\"],1),\n",
    "                     #batch_input_shape=(1,params[\"timesteps\"],params[\"dense_units\"]), \n",
    "                     stateful=True,\n",
    "                     return_sequences= True if n > 1 else False,\n",
    "                     dropout=params[\"lstm1_dropout\"],\n",
    "                     recurrent_dropout=params[\"lstm1_recurrent_dropout\"],\n",
    "                     activity_regularizer=regularizers.l2(l=params[\"lstm1_l2reg\"]),\n",
    "                )\n",
    "                 \n",
    "    if \"bidirectional_lstms\" in params and params[\"bidirectional_lstms\"] == True:\n",
    "        lstm1 = Bidirectional(lstm1, batch_input_shape=(1,params[\"timesteps\"],1))#params[\"dense_units\"])) #default mode is concat\n",
    "\n",
    "    layers.append(lstm1)\n",
    "                 \n",
    "    if n == 1:\n",
    "        return layers\n",
    "        \n",
    "    lstm2 = LSTM(params[\"lstm2_units\"],\n",
    "                     stateful=True,\n",
    "                     return_sequences = True if n > 2 else False,\n",
    "                     dropout=params[\"lstm2_dropout\"],\n",
    "                     recurrent_dropout=params[\"lstm2_recurrent_dropout\"],\n",
    "                     activity_regularizer=regularizers.l2(l=params[\"lstm2_l2reg\"]),\n",
    "                    )\n",
    "                 \n",
    "    if \"bidirectional_lstms\" in params and params[\"bidirectional_lstms\"] == True:\n",
    "        lstm2 = Bidirectional(lstm2, batch_input_shape=(1,params[\"timesteps\"],params[\"dense_units\"])) #default mode is concat  \n",
    "    \n",
    "    layers.append(lstm2)\n",
    "                 \n",
    "    if n == 2:\n",
    "        return layers\n",
    "                \n",
    "    \n",
    "    lstm3 = LSTM(params[\"lstm3_units\"],\n",
    "                stateful=True,\n",
    "                return_sequences=False,\n",
    "                dropout=params[\"lstm3_dropout\"],\n",
    "                recurrent_dropout=params[\"lstm3_recurrent_dropout\"],\n",
    "                activity_regularizer=regularizers.l2(l=params[\"lstm3_l2reg\"]),\n",
    "               )\n",
    "                 \n",
    "    if \"bidirectional_lstms\" in params and params[\"bidirectional_lstms\"] == True:\n",
    "        lstm3 = Bidirectional(lstm3,batch_input_shape=(1,params[\"timesteps\"],params[\"dense_units\"])) #default mode is concat  \n",
    "                 \n",
    "    layers.append(lstm3)\n",
    "                 \n",
    "    return layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-23T05:45:11.699435Z",
     "start_time": "2019-05-23T05:45:11.696439Z"
    }
   },
   "outputs": [],
   "source": [
    "#I have been using Mean Exp Sq Error instead of Mean Sq Error (I am experimenting with both)\n",
    "#Hoping exp would put more pressure on the model to capture spikes.\n",
    "\n",
    "#You may need to change this \n",
    "#K is keras.backend\n",
    "\n",
    "#Not sure if you need K.mean as it is only one value you predict not all cameras at once.\n",
    "def exp_loss(yTrue,yPred):\n",
    "    return K.mean(K.exp(K.square(yTrue - yPred,)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-23T05:45:21.070408Z",
     "start_time": "2019-05-23T05:45:21.063407Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "paramss = []\n",
    "paramss.append({\"desc\" : \"testing_bidirectional\", \"timesteps\" : 19*21, \"loss\" : \"mse\",\n",
    "                \"stack_lstm_count\" : 2, \"bidirectional_lstms\" : False,\n",
    "                \"lstm1_units\" : 80, \"lstm1_dropout\" : 0, \"lstm1_recurrent_dropout\" : 0, \"lstm1_l2reg\" : 0.,\n",
    "                \"lstm2_units\" : 80, \"lstm2_dropout\" : 0.6, \"lstm2_recurrent_dropout\" : 0, \"lstm2_l2reg\" : 0.05,\n",
    "                \"dense_units\" : 58*3, \"dense_dropout\" : 0.4, \"dense_l2reg\" : 0.001, \"dense_activation\" : \"LeakyReLU\", \n",
    "                \"alpha\": 0.1})\n",
    "\n",
    "paramss.append({\"desc\" : \"mimic_v1_stacked_after_refactor\", \"timesteps\" : 19*21, \"loss\" : \"mse\",\n",
    "                \"stack_lstm_count\" : 2, \n",
    "                \"lstm1_units\" : 80, \"lstm1_dropout\" : 0, \"lstm1_recurrent_dropout\" : 0, \"lstm1_l2reg\" : 0.,\n",
    "                \"lstm2_units\" : 80, \"lstm2_dropout\" : 0.6, \"lstm2_recurrent_dropout\" : 0, \"lstm2_l2reg\" : 0.05,\n",
    "                \"dense_units\" : 58*3, \"dense_dropout\" : 0.6, \"dense_l2reg\" : 0.001, \"dense_activation\" : \"LeakyReLU\",\n",
    "               })\n",
    "\n",
    "paramss.append({\"desc\" : \"mimic_v1_stacked_with_mse_loss\", \"timesteps\" : 19*21, \"loss\" : \"mse\",\n",
    "                \"stack_lstm_count\" : 2, \n",
    "                \"lstm1_units\" : 80, \"lstm1_dropout\" : 0, \"lstm1_recurrent_dropout\" : 0, \"lstm1_l2reg\" : 0.,\n",
    "                \"lstm2_units\" : 80, \"lstm2_dropout\" : 0.4, \"lstm2_recurrent_dropout\" : 0, \"lstm2_l2reg\" : 0.05,\n",
    "                \"dense_units\" : 58*3, \"dense_dropout\" : 0.6, \"dense_l2reg\" : 0.001, \"dense_activation\" : \"LeakyReLU\",\n",
    "                \"alpha\": 0.1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(params):\n",
    "    #TODO: implement you model here. and return the model object.\n",
    "    # you should start with a simple model that uses a relatively small LSTM to predict.\n",
    "    model = Sequential()\n",
    "    #lyrs = []\n",
    "    lyrs = get_lstm_layers(params)\n",
    "    \n",
    "    for layr in lyrs:\n",
    "        #print(layr.input_spec)\n",
    "        #(batch_size, timesteps, units)\n",
    "        model.add(layr)\n",
    "    \n",
    "    #\n",
    "        \n",
    "    \n",
    "    model.add(Dense(1))#, activation = params[\"dense_activation\"]))\n",
    "    \n",
    "    if(params[\"dense_activation\"] == \"LeakyReLU\"):\n",
    "        model.add(LeakyReLU(alpha= params[\"alpha\"]))\n",
    "        \n",
    "    else:\n",
    "        model.add(Activation(params[\"dense_activation\"]))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "camlist = [4, 5, 6, 7, 8, 9, 15, 20, 26, 30, 32, 34, 37, 39, 40, 42, 44, 45, 46, 47, 48, 49, 52, 53, 54, 56, 57, 58, 61, 62, 64, 70, 73, 75, 78, 79, 80, 81, 83, 84, 86, 87, 88, 91, 93, 95, 96, 97, 98, 101, 103, 107, 108, 111, 117, 118, 119, 120]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-24T20:36:29.085917Z",
     "start_time": "2019-05-24T20:36:29.054831Z"
    }
   },
   "outputs": [],
   "source": [
    "# current_time = lambda: int(round(time()*1000))\n",
    "\n",
    "# print(str(current_time()))\n",
    "\n",
    "# nsets = len(paramss)\n",
    "\n",
    "# print(nsets)\n",
    "\n",
    "\n",
    "# #print(CURRENT_TIME)\n",
    "\n",
    "# losslist = []\n",
    "\n",
    "# msqlist = []\n",
    "\n",
    "# msqfname = \"msq_per_cam.csv\"\n",
    "\n",
    "# lossfname = \"loss_per cam.csv\"\n",
    "\n",
    "# total_loss = 0.0\n",
    "\n",
    "# total_msq = 0.0\n",
    "\n",
    "# # numpy.savetxt(msqfname, a, delimiter=\"\\n\")\n",
    "\n",
    "# # numpy.savetext(lossfname, a, delimiter = '\\n')\n",
    "\n",
    "# for camid in camlist:\n",
    "\n",
    "#     for params in paramss: \n",
    "#         #this way you can manually/automatically define your hyperparams to run and then let it run all the configs\n",
    "#         #there are other ways for hyperparam tuning but I wrote it this way from scratch for my stuff and it seems to do its job.\n",
    "#         #we might need a final hyper param tuning were it does a grid search of some of the parameters or a smart state space search (hopefully implemented already in a tool like Microsoft NNI)\n",
    "\n",
    "#         model = get_model(params)\n",
    "\n",
    "#         model.compile(optimizer=Adam(lr=0.001,clipnorm=1.), loss=params[\"loss\"], metrics=[\"mse\"])\n",
    "\n",
    "\n",
    "\n",
    "#         print(model.summary())\n",
    "\n",
    "#         #fname = str(i)+'.png'\n",
    "#         #plot_model(model, to_file= fname, show_shapes = True, show_layer_names = True)\n",
    "\n",
    "#         # If you are going to use tensorboard for visualization you need to pass a TensorBoard callback to the fit function.\n",
    "#         # The default one, plots train and evaluation losses separately.\n",
    "#         # I used this one:\n",
    "#         # https://urldefense.proofpoint.com/v2/url?u=https-3A__stackoverflow.com_questions_47877475_keras-2Dtensorboard-2Dplot-2Dtrain-2Dand-2Dvalidation-2Dscalars-2Din-2Da-2Dsame-2Dfigure&d=DwIGaQ&c=sJ6xIWYx-zLMB3EPkvcnVg&r=_syK-BFuRYpXO3xxhpNENA&m=VESWBdIR2JRGr_zyNJ4AgZiGwnPzAt-BfFiuOgvF-40&s=yheitMrc8ziNbiYRUAUL5z1ArglNu5xYtwXCkPKF8O0&e=\n",
    "#         # so that it would plot them in the same figure.\n",
    "\n",
    "#         # LOGDIR = \"logs/{}[{}]\".format(params[\"desc\"], CURRENT_TIME )     \n",
    "#         # tensorboard = TrainValTensorBoard(log_dir= LOGDIR)\n",
    "\n",
    "#         # One more thing about tensorboard callback: write_grads seems broken and not fixed yet. It would have been nice to see the gradients..\n",
    "#         # write_grads=True, histogram_freq= 2, batch_size=1 )\n",
    "\n",
    "#         #Earlystopping would stop training if the model validation (evaluation) loss does not improve over \n",
    "#         #patience epochs for at least min_delta.\n",
    "#         es = EarlyStopping(monitor=\"val_loss\", patience=10, min_delta=0.0009, restore_best_weights=True)\n",
    "\n",
    "#         bmodelname = str(camid)+\"_\"+str(current_time())+\".hdf5\"\n",
    "\n",
    "#         print(bmodelname)\n",
    "\n",
    "#         bmodelpath = \"D:/Code/bestmodel/\"+bmodelname\n",
    "\n",
    "#         print(bmodelpath)\n",
    "\n",
    "#         mc = ModelCheckpoint(bmodelpath, monitor = 'val_mean_squared_error', verbose = 1, save_best_only= True, \n",
    "#                             save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "#     #     #logging parameters to text file\n",
    "#         with open('params_log_lstm_per_camera_for_london.txt', 'a') as f:\n",
    "#             print(params, file=f)\n",
    "\n",
    "#         train_gen = get_data_generator(df, camid, params[\"timesteps\"], mode = \"train\")\n",
    "#     #     #don't reuse generator as it might be messed up.\n",
    "\n",
    "#         #print(train_gen)\n",
    "\n",
    "#         val_gen = get_data_generator(df, camid, params[\"timesteps\"], mode=\"eval\")\n",
    "\n",
    "#         #csv_logger = CSVLogger(lname, append=True, separator=';')\n",
    "\n",
    "#         #fname.write(str(params))\n",
    "\n",
    "#         history = model.fit_generator(train_gen,\n",
    "#                                        epochs = 250,\n",
    "#                                        steps_per_epoch= L-TIMESTEPS,\n",
    "#                                        validation_data = val_gen,\n",
    "#                                        validation_steps = len(df) - L, \n",
    "#                                        callbacks=[es, mc]#, csv_logger] #tensorboard goes here\n",
    "#                                       )\n",
    "\n",
    "#         bestmod = load_model(bmodelpath)\n",
    "\n",
    "#         test_gen = get_data_generator(df, camid, params[\"timesteps\"], mode = \"predict\")\n",
    "\n",
    "#         eval = bestmod.evaluate_generator(val_gen, steps = 174)\n",
    "        \n",
    "#         total_loss = total_loss+eval[0]\n",
    "#         total_msq = total_msq+eval[1]\n",
    "        \n",
    "#         losslist.append(eval[0])\n",
    "#         msqlist.append(eval[1])\n",
    "#         print(eval)\n",
    "#         #print(h.history.keys())\n",
    "\n",
    "\n",
    "# #         npa = np.array(history.history['val_loss'])\n",
    "# #         print(\"avg val loss: \"+ str(np.mean(npa)))\n",
    "\n",
    "# #        fname.write(str(np.mean(npa)))\n",
    "\n",
    "#         #plt.plot(history.history['loss'])\n",
    "#         plt.plot(history.history['val_loss'])\n",
    "#         #plt.plot(history.history['mean_squared_error'])\n",
    "#         plt.plot(history.history['val_mean_squared_error'])\n",
    "#         plt.ylabel('loss')\n",
    "#         plt.xlabel('epoch')\n",
    "#         plt.legend(['train', 'val'], loc = 'upper right')\n",
    "#         plt.show()    \n",
    "\n",
    "#         del model \n",
    "#         del history\n",
    "#         K.clear_session() #to hopefully prevent slow down after a few models have run..\n",
    "\n",
    "\n",
    "# #calculate mean of loss and mean of msq\n",
    "# meanlosscam = total_loss/(len(losslist))\n",
    "# meanmsqcam = total_msq/len(msqlist)\n",
    "\n",
    "# losslist.append(meanlosscam)#final entry in each csv file would be the final av.loss/av.error\n",
    "# msqlist.append(meanmsqcam)\n",
    "\n",
    "# #convert to numpy array so as to later convert to csv\n",
    "# np.asarray(losslist)\n",
    "# np.asarray(msqlist)\n",
    "\n",
    "# np.savetxt(lossfname, losslist)\n",
    "# np.savetxt(msqfname, msqlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1565291597012\n",
      "[[]]\n",
      "[[]]\n",
      "cam_num4\n",
      "Index: 0\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_7 (LSTM)                (1, 399, 80)              26240     \n",
      "_________________________________________________________________\n",
      "lstm_8 (LSTM)                (1, 80)                   51520     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (1, 1)                    81        \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (1, 1)                    0         \n",
      "=================================================================\n",
      "Total params: 77,841\n",
      "Trainable params: 77,841\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "4_1565291597551.hdf5\n",
      "D:/4_1565291597551.hdf5\n",
      "Epoch 1/250\n",
      "437/437 [==============================] - 118s 270ms/step - loss: 0.0223 - mean_squared_error: 0.0170 - val_loss: 0.0270 - val_mean_squared_error: 0.0241\n",
      "\n",
      "Epoch 00001: val_mean_squared_error improved from inf to 0.02405, saving model to D:/4_1565291597551.hdf5\n",
      "Epoch 2/250\n",
      "437/437 [==============================] - 118s 270ms/step - loss: 0.0152 - mean_squared_error: 0.0124 - val_loss: 0.0204 - val_mean_squared_error: 0.0176\n",
      "\n",
      "Epoch 00002: val_mean_squared_error improved from 0.02405 to 0.01761, saving model to D:/4_1565291597551.hdf5\n",
      "Epoch 3/250\n",
      "437/437 [==============================] - 119s 272ms/step - loss: 0.0129 - mean_squared_error: 0.0109 - val_loss: 0.0185 - val_mean_squared_error: 0.0169\n",
      "\n",
      "Epoch 00003: val_mean_squared_error improved from 0.01761 to 0.01690, saving model to D:/4_1565291597551.hdf5\n",
      "Epoch 4/250\n",
      "437/437 [==============================] - 120s 275ms/step - loss: 0.0104 - mean_squared_error: 0.0089 - val_loss: 0.0131 - val_mean_squared_error: 0.0109\n",
      "\n",
      "Epoch 00004: val_mean_squared_error improved from 0.01690 to 0.01094, saving model to D:/4_1565291597551.hdf5\n",
      "Epoch 5/250\n",
      "437/437 [==============================] - 118s 269ms/step - loss: 0.0092 - mean_squared_error: 0.0078 - val_loss: 0.0119 - val_mean_squared_error: 0.0104\n",
      "\n",
      "Epoch 00005: val_mean_squared_error improved from 0.01094 to 0.01042, saving model to D:/4_1565291597551.hdf5\n",
      "Epoch 6/250\n",
      "437/437 [==============================] - 118s 271ms/step - loss: 0.0083 - mean_squared_error: 0.0072 - val_loss: 0.0099 - val_mean_squared_error: 0.0084\n",
      "\n",
      "Epoch 00006: val_mean_squared_error improved from 0.01042 to 0.00843, saving model to D:/4_1565291597551.hdf5\n",
      "Epoch 7/250\n",
      "437/437 [==============================] - 118s 270ms/step - loss: 0.0083 - mean_squared_error: 0.0074 - val_loss: 0.0103 - val_mean_squared_error: 0.0087\n",
      "\n",
      "Epoch 00007: val_mean_squared_error did not improve from 0.00843\n",
      "Epoch 8/250\n",
      "437/437 [==============================] - 119s 273ms/step - loss: 0.0076 - mean_squared_error: 0.0068 - val_loss: 0.0093 - val_mean_squared_error: 0.0082\n",
      "\n",
      "Epoch 00008: val_mean_squared_error improved from 0.00843 to 0.00817, saving model to D:/4_1565291597551.hdf5\n",
      "Epoch 9/250\n",
      "437/437 [==============================] - 126s 287ms/step - loss: 0.0082 - mean_squared_error: 0.0075 - val_loss: 0.0098 - val_mean_squared_error: 0.0089\n",
      "\n",
      "Epoch 00009: val_mean_squared_error did not improve from 0.00817\n",
      "Epoch 10/250\n",
      "437/437 [==============================] - 120s 275ms/step - loss: 0.0073 - mean_squared_error: 0.0066 - val_loss: 0.0092 - val_mean_squared_error: 0.0083\n",
      "\n",
      "Epoch 00010: val_mean_squared_error did not improve from 0.00817\n",
      "Epoch 11/250\n",
      "437/437 [==============================] - 126s 289ms/step - loss: 0.0092 - mean_squared_error: 0.0084 - val_loss: 0.0097 - val_mean_squared_error: 0.0089\n",
      "\n",
      "Epoch 00011: val_mean_squared_error did not improve from 0.00817\n",
      "Epoch 12/250\n",
      "437/437 [==============================] - 125s 287ms/step - loss: 0.0076 - mean_squared_error: 0.0071 - val_loss: 0.0097 - val_mean_squared_error: 0.0090\n",
      "\n",
      "Epoch 00012: val_mean_squared_error did not improve from 0.00817\n",
      "Epoch 13/250\n",
      "437/437 [==============================] - 134s 306ms/step - loss: 0.0073 - mean_squared_error: 0.0068 - val_loss: 0.0087 - val_mean_squared_error: 0.0079\n",
      "\n",
      "Epoch 00013: val_mean_squared_error improved from 0.00817 to 0.00795, saving model to D:/4_1565291597551.hdf5\n",
      "Epoch 14/250\n",
      "437/437 [==============================] - 126s 288ms/step - loss: 0.0074 - mean_squared_error: 0.0069 - val_loss: 0.0101 - val_mean_squared_error: 0.0095\n",
      "\n",
      "Epoch 00014: val_mean_squared_error did not improve from 0.00795\n",
      "Epoch 15/250\n",
      "437/437 [==============================] - 122s 280ms/step - loss: 0.0069 - mean_squared_error: 0.0065 - val_loss: 0.0088 - val_mean_squared_error: 0.0082\n",
      "\n",
      "Epoch 00015: val_mean_squared_error did not improve from 0.00795\n",
      "Epoch 16/250\n",
      "437/437 [==============================] - 126s 288ms/step - loss: 0.0075 - mean_squared_error: 0.0071 - val_loss: 0.0092 - val_mean_squared_error: 0.0085\n",
      "\n",
      "Epoch 00016: val_mean_squared_error did not improve from 0.00795\n",
      "Epoch 17/250\n",
      "437/437 [==============================] - 125s 286ms/step - loss: 0.0070 - mean_squared_error: 0.0066 - val_loss: 0.0092 - val_mean_squared_error: 0.0086\n",
      "\n",
      "Epoch 00017: val_mean_squared_error did not improve from 0.00795\n",
      "Epoch 18/250\n",
      "437/437 [==============================] - 128s 294ms/step - loss: 0.0075 - mean_squared_error: 0.0071 - val_loss: 0.0101 - val_mean_squared_error: 0.0096\n",
      "\n",
      "Epoch 00018: val_mean_squared_error did not improve from 0.00795\n",
      "Epoch 19/250\n",
      "437/437 [==============================] - 122s 279ms/step - loss: 0.0066 - mean_squared_error: 0.0063 - val_loss: 0.0093 - val_mean_squared_error: 0.0088\n",
      "\n",
      "Epoch 00019: val_mean_squared_error did not improve from 0.00795\n",
      "Epoch 20/250\n",
      "437/437 [==============================] - 122s 278ms/step - loss: 0.0068 - mean_squared_error: 0.0065 - val_loss: 0.0117 - val_mean_squared_error: 0.0111\n",
      "\n",
      "Epoch 00020: val_mean_squared_error did not improve from 0.00795\n",
      "Epoch 21/250\n",
      "437/437 [==============================] - 123s 281ms/step - loss: 0.0070 - mean_squared_error: 0.0066 - val_loss: 0.0100 - val_mean_squared_error: 0.0095\n",
      "\n",
      "Epoch 00021: val_mean_squared_error did not improve from 0.00795\n",
      "Epoch 22/250\n",
      "437/437 [==============================] - 122s 280ms/step - loss: 0.0065 - mean_squared_error: 0.0062 - val_loss: 0.0106 - val_mean_squared_error: 0.0101\n",
      "\n",
      "Epoch 00022: val_mean_squared_error did not improve from 0.00795\n",
      "Epoch 23/250\n",
      "437/437 [==============================] - 124s 283ms/step - loss: 0.0067 - mean_squared_error: 0.0064 - val_loss: 0.0128 - val_mean_squared_error: 0.0122\n",
      "\n",
      "Epoch 00023: val_mean_squared_error did not improve from 0.00795\n",
      "[0.00928168654344068, 0.00851034083845417]\n",
      "[0.00928168654344068]\n",
      "[0.00851034083845417]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#CURRENT_TIME = str(datetime.now().time())\n",
    "\n",
    "current_time = lambda: int(round(time()*1000))\n",
    "\n",
    "print(str(current_time()))\n",
    "\n",
    "camlist = [4]#, 5]#, 6, 7]#, 8, 9, 15, 20, 26, 30, 32, 34, 37, 39, 40, 42, 44, 45, 46, 47, 48, 49, 52, 53, 54, 56, 57, 58, 61, 62, 64, 70, 73, 75, 78, 79, 80, 81, 83, 84, 86, 87, 88, 91, 93, 95, 96, 97, 98, 101, 103, 107, 108, 111, 117, 118, 119, 120]\n",
    "\n",
    "#print(CURRENT_TIME)\n",
    "\n",
    "num_par_sets = len(paramss)\n",
    "\n",
    "#list of lists per parameter set\n",
    "setlosslist = []\n",
    "setmsqlist = []\n",
    "\n",
    "for i in range(0,num_par_sets):\n",
    "    setlosslist.append([])\n",
    "    setmsqlist.append([])\n",
    "    \n",
    "print(setlosslist)\n",
    "print(setmsqlist)\n",
    "\n",
    "msqfname = \"msq_per_cam.csv\"\n",
    "\n",
    "lossfname = \"loss_per cam.csv\"\n",
    "\n",
    "# numpy.savetxt(msqfname, a, delimiter=\"\\n\")\n",
    "\n",
    "# numpy.savetext(lossfname, a, delimiter = '\\n')\n",
    "\n",
    "#setlosslist = [[4thcam_loss, 5thcamloss, 6thcamloss...],[4thcamloss, 5thcamloss, 6thcamloss],[4thcamloss, 5thcamloss, 6thcamloss]]\n",
    "\n",
    "for camid in camlist:\n",
    "    \n",
    "    print(\"cam_num\"+ str(camid))\n",
    "    \n",
    "    index = 0\n",
    "    \n",
    "    for params in paramss: \n",
    "        \n",
    "        print(\"Index: \"+str(index))\n",
    "        #this way you can manually/automatically define your hyperparams to run and then let it run all the configs\n",
    "        #there are other ways for hyperparam tuning but I wrote it this way from scratch for my stuff and it seems to do its job.\n",
    "        #we might need a final hyper param tuning were it does a grid search of some of the parameters or a smart state space search (hopefully implemented already in a tool like Microsoft NNI)\n",
    "\n",
    "        model = get_model(params)\n",
    "\n",
    "        model.compile(optimizer=Adam(lr=0.001,clipnorm=1.), loss=params[\"loss\"], metrics=[\"mse\"])\n",
    "\n",
    "\n",
    "\n",
    "        print(model.summary())\n",
    "\n",
    "        #fname = str(i)+'.png'\n",
    "        #plot_model(model, to_file= fname, show_shapes = True, show_layer_names = True)\n",
    "\n",
    "        # If you are going to use tensorboard for visualization you need to pass a TensorBoard callback to the fit function.\n",
    "        # The default one, plots train and evaluation losses separately.\n",
    "        # I used this one:\n",
    "        # https://urldefense.proofpoint.com/v2/url?u=https-3A__stackoverflow.com_questions_47877475_keras-2Dtensorboard-2Dplot-2Dtrain-2Dand-2Dvalidation-2Dscalars-2Din-2Da-2Dsame-2Dfigure&d=DwIGaQ&c=sJ6xIWYx-zLMB3EPkvcnVg&r=_syK-BFuRYpXO3xxhpNENA&m=VESWBdIR2JRGr_zyNJ4AgZiGwnPzAt-BfFiuOgvF-40&s=yheitMrc8ziNbiYRUAUL5z1ArglNu5xYtwXCkPKF8O0&e=\n",
    "        # so that it would plot them in the same figure.\n",
    "\n",
    "        # LOGDIR = \"logs/{}[{}]\".format(params[\"desc\"], CURRENT_TIME )     \n",
    "        # tensorboard = TrainValTensorBoard(log_dir= LOGDIR)\n",
    "\n",
    "        # One more thing about tensorboard callback: write_grads seems broken and not fixed yet. It would have been nice to see the gradients..\n",
    "        # write_grads=True, histogram_freq= 2, batch_size=1 )\n",
    "\n",
    "        #Earlystopping would stop training if the model validation (evaluation) loss does not improve over \n",
    "        #patience epochs for at least min_delta.\n",
    "        es = EarlyStopping(monitor=\"val_loss\", patience=10, min_delta=0.0009, restore_best_weights=True)\n",
    "\n",
    "        bmodelname = str(camid)+\"_\"+str(current_time())+\".hdf5\"\n",
    "\n",
    "        print(bmodelname)\n",
    "\n",
    "        bmodelpath = \"D:/\"+bmodelname\n",
    "\n",
    "        print(bmodelpath)\n",
    "\n",
    "        mc = ModelCheckpoint(bmodelpath, monitor = 'val_mean_squared_error', verbose = 1, save_best_only= True, \n",
    "                            save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "    #     #logging parameters to text file\n",
    "        with open('params_log_lstm_per_camera_for_london.txt', 'a') as f:\n",
    "            print(params, file=f)\n",
    "\n",
    "        train_gen = get_data_generator(df, camid, params[\"timesteps\"], mode = \"train\")\n",
    "    #     #don't reuse generator as it might be messed up.\n",
    "\n",
    "        #print(train_gen)\n",
    "\n",
    "        val_gen = get_data_generator(df, camid, params[\"timesteps\"], mode=\"eval\")\n",
    "\n",
    "        #csv_logger = CSVLogger(lname, append=True, separator=';')\n",
    "\n",
    "        #fname.write(str(params))\n",
    "\n",
    "        history = model.fit_generator(train_gen,\n",
    "                                       epochs = 250,\n",
    "                                       steps_per_epoch= L-TIMESTEPS,\n",
    "                                       validation_data = val_gen,\n",
    "                                       validation_steps = len(df) - L, \n",
    "                                       callbacks=[es, mc]#, csv_logger] #tensorboard goes here\n",
    "                                      )\n",
    "\n",
    "        bestmod = load_model(bmodelpath)\n",
    "\n",
    "        test_gen = get_data_generator(df, camid, params[\"timesteps\"], mode = \"predict\")\n",
    "\n",
    "        eval = bestmod.evaluate_generator(val_gen, steps = 174)\n",
    "        print(eval)\n",
    "        \n",
    "        setlosslist[index].append(eval[0])\n",
    "        print(setlosslist[index])\n",
    "        setmsqlist[index].append(eval[1])\n",
    "        print(setmsqlist[index])\n",
    "        \n",
    "        index = index+1\n",
    "        \n",
    "        \n",
    "        #print(h.history.keys())\n",
    "        #plt.plot(history.history['loss'])\n",
    "        #plt.plot(history.history['val_loss'])\n",
    "        plt.plot(history.history['mean_squared_error'])\n",
    "        plt.plot(history.history['val_mean_squared_error'])\n",
    "        plt.ylabel('loss')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.legend(['train', 'val'], loc = 'upper right')\n",
    "        plt.show()    \n",
    "\n",
    "        del model \n",
    "        del history\n",
    "        K.clear_session() #to hopefully prevent slow down after a few models have run..\n",
    "    \n",
    "\n",
    "\n",
    "#for each parameter, 58 entries which are losses/errors for 58 different cameras. \n",
    "#Find the parameter set with least mean of errors\n",
    "#write out that parameter set's error list to a csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(setmsqlist)\n",
    "print(len(setmsqlist[0]))\n",
    "listofmeanmsq = []\n",
    "\n",
    "for i in range(0, num_par_sets):\n",
    "    currlist = setmsqlist[i]\n",
    "    meanmsq = sum(currlist)/len(camlist)\n",
    "    listofmeanmsq.append(meanmsq)\n",
    "    \n",
    "print(listofmeanmsq)\n",
    "minindex = np.argmin(listofmeanmsq)\n",
    "\n",
    "print(minindex)\n",
    "\n",
    "finlist = setmsqlist[minindex]\n",
    "\n",
    "np.asarray(finlist)\n",
    "np.savetext(msqfname, finlist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
